---
toc-title: "Chapter 2"
---

# Preliminaries: Communicating Systems and Games {#sec-preliminaries}

::: {.content-visible when-format="html"}
{{< include style/macros-html.md >}}
{{< include style/macros.md >}}
:::

::::{#related-2 .column-margin}
`\vspace{-2.1em}`{=latex}
{{< paragraph_heading "Related publications." >}}
This chapter is based on my introductory lectures and Isabelle/HOL theory on behavioral equivalences, given in the Master course “Research at Work” at TU Berlin in Winter 2023/24.
We aim to be mostly compatible with the textbook *Reactive systems* [@ails2007reactiveSystems].
::::

The core background of this thesis is the *trinity of characterizations for behavioral equivalences*: relational, modal, and game-theoretic.

This chapter takes a tour into the field of formalisms used to model programs and communicating systems, which are accompanied by many notions for behavioral equivalence and refinement to relate or distinguish their models.
As core formalisms we use transition systems and the Calculus of Communicating Systems (CCS) in @sec-programs.

The tour is *agnostic*, building on the basic formalism of *labeled transition systems* and standard equivalences such as *trace equivalence* and *bisimilarity*.
Simultaneously, the approach is *opinionated*, focusing on Milner's tradition of concurrency theory with a strong pull towards *game characterizations*.
<!-- The very core concepts are described in @sec-programs. -->

@fig-equivalence-big-picture shows the scaffold of this section along the trinity, instantiated to the classic notion of bisimilarity:

- @sec-behavioral-eq introduces (among other notions) bisimilarity through its *relational characterization* in terms of symmetric simulation relations.
- @sec-hml treats the dual connection of bisimilarity and the distinguishing powers of a *modal logic*, known as the *Hennessy--Milner theorem*.
- @sec-games shows that both, the relations to validate bisimilarity and the modal formulas to falsify it, appear as certificates of strategies in a *reachability game* where an attacker tries to tell states apart and a defender tries to prevent this.

::: {#fig-equivalence-big-picture fig-env="figure*"}
```tikz
\begin{adjustbox}{max width=\textwidth, center}
  \begin{tikzpicture}[auto,node distance=1.05cm,
    algstep/.style={minimum width=4.4cm, minimum height=1.2cm, draw=gray, rectangle,align=center,rounded corners}]
    \node[algstep, draw=TealBlue] (Bisim) {$p \beq{B} q$\\ $p$ and $q$ are bisimilar};
    \node[algstep, draw=TealBlue, right of=Bisim, node distance=7.4cm] (NotBisim) {$p \nbeq{B} q$ \\ $p$ and $q$ are not bisimilar};
    \node[below of=Bisim, text=TealBlue, rotate=270, label={[align=center]270:Def.~\ref{def-bisimilarity}}] (Biff) {$:\!\!\iff$};
    \node[below of=NotBisim, gray, rotate=270] (NBiff) {$\iff$};
    \node[algstep, draw=TealBlue, below of=Biff] (Rel) {There is bisimulation $\rel{R}$\\such that $(p,q) \in \rel{R}$};
    \node[algstep, draw=DarkViolet, below of=NBiff] (Distinction) {Some $\varphi \in \hml$\\distinguishes $p$ from $q$};
    \node[below of=Rel, text=Peach, rotate=270, label={[align=right]270:Stirling's\\characterization}, label={[align=left]90:Thm.~\ref{thm-bisim-game-characterization}}] (Siff) {$\iff$};
    \node[below of=Distinction, text=Peach, rotate=270, label=90:{Thm.~\ref{thm-game-formulas}}] (Giff) {$\iff$};
    \node[algstep, draw=Peach, below of=Siff] (DefenderWins) {Defender wins bisimulation\\game from $[p,q]$};
    \node[algstep, draw=Peach, below of=Giff] (AttackerWins) {Attacker wins bisimulation\\game from $[p,q]$};
    \path
      (Bisim) edge[draw=TealBlue] node[label=below:{Def.~\ref{def-bisimilarity}}] {XOR} (NotBisim)
      (Rel) edge[draw=DarkViolet] node[label={[align=center]below:Hennessy--Milner\\Thm.~\ref{thm-hennessy-milner}}] {XOR} (Distinction)
      (DefenderWins) edge[draw=Peach] node[label={[align=center]below:Determinacy\\of games}] {XOR} (AttackerWins);
    \node[text=TealBlue, right=2mm of NotBisim] (Sec22) {Section \ref{sec-behavioral-eq}};
    \node[text=DarkViolet, right=2mm of Distinction] (Sec23) {Section \ref{sec-hml}};
    \node[text=Peach, right=2mm of AttackerWins] (Sec24) {Section \ref{sec-games}};
  \end{tikzpicture}
\end{adjustbox}
```

Core correlations for bisimilarity between relational definition, modal distinguishability, and equivalence game.
:::

A reader familiar with the contents of @fig-equivalence-big-picture might mostly skim through this chapter of preliminaries (although they are quite exciting!).
This chapter aims to seed two core insights for the upcoming chapters:

::: {#idea-games .callout-idea .callout-tip}
#### It's all a game!
Equivalence games are a versatile way to handle behavioral equivalences and obtain decision procedures.
The Hennessy--Milner theorem appears as a shadow of the determinacy of the bisimulation reachability game.
:::

We will move towards motivating the games through logics.

::: {#idea-modal-first .callout-idea .callout-tip}
#### Modal first!

Modal characterizations allow a uniform handling of the hierarchy of equivalences.
Productions in grammars of potential distinguishing formulas translate to game rules for equivalence games.
:::

Both points might seem non-standard to those more accustomed to relational or denotational definitions of behavioral equivalences.
To provide them with a bridge, our presentation starts with relational and denotational definitions---but once we have crossed this bridge, we will stay in the realm of games and logics, putting these first.

::::{.content-visible when-format="html" .column-margin}
{{< contents related-2 >}}
::::

## Behavior of Programs {#sec-programs}

Every computer scientist has some model in their head of what it is that their algorithms and programs are doing.
Usually these models are wrong,^[
  But some are useful, as the saying goes.
] especially, once concurrency enters the picture.
The area of *formal methods* tries to make models sufficiently precise that one, at least, can say what went wrong.

### Labeled Transition Systems

Labeled transition systems are the standard formalism to discretely express the state space of programs, algorithms, and more.
One can think of them as nondeterministic finite automata without finiteness constraint.

::: {#def-ts}
#### Transition systems

A *transition system* $\system=(\states,\actions,\step{})$ consists of

- $\states$, a set of *states,*
- $\actions$, a set of *actions,* and
- ${\step{}} ⊆ \states × \actions × \states$, a *transition relation*.

We use infix notation for arrows, that is, $p \step{\alpha} p'$ stands for $(p, \alpha, p') \in {\step{}}$.
We write $\derivatives{p, α}$ for the set of *derivative states* $\set{p' \mid p \step α p'}$
and $\initials{p}$ for the set of enabled actions $\set{α \mid \exists p' \ldotp p \step α p'}$.
We sometimes lift transitions to sets $P, P' \subseteq \states$ with $P \step{\alpha} P'$ iff $P' = \set{p' \in \states \mid \exists p \in P \ldotp p \step{\alpha} p'}$.
:::

There is a canonical example used to discuss equivalences within transition systems, which we want to draw from.
We will take the formulation that Henzinger used at CAV'23 as seen in @fig-henzinger.

::: {#fig-henzinger .column-margin}

{{< pic "img/henzinger.jpg" >}}

Tom Henzinger employing @exm-ts during CAV'23 to stress that “games are everywhere.”
(Incidentally, this chapter follows a similar mission.)
:::

::: {#exm-ts}
#### A classic example

Let us consider the labeled transition system $\system_\literal{PQ} = (\set{\literal P, \literal{p_a}, \literal{p_b}, \literal{p_1}, \literal{p_2}, \literal Q, \literal{q_{ab}}, \literal{q_1}, \literal{q_2}}, \set{\literal a, \literal b, τ}, \step{}_\literal{PQ})$ given by the graph in @fig-ts-determinism.

::::{#fig-ts-determinism fig-pos="tbp"}
```tikz
\begin{tikzpicture}[->,auto,node distance=1.9 cm]
  \node[] (P){$\literal{P}$};
  \node[below left of=P] (PA){$\literal{p_a}$};
  \node[below right of=P] (PB){$\literal{p_b}$};
  \node[below of=PA] (P1){$\literal{p_1}$};
  \node[below of=PB] (P2){$\literal{p_2}$};
  \path
    (P)
      edge node[swap] {$\tau$} (PA)
      edge node {$\tau$} (PB)
    (PA)
      edge node {$\literal{a}\vphantom{\literal{b}}$} (P1)
    (PB)
      edge node {$\literal{b}$} (P2);

  \node[right=5cm of P] (Q){$\literal{Q}$};
  \node[below of=Q] (QAB){$\literal{q_{ab}}$};
  \node[below left of=QAB] (Q1){$\literal{q_1}$};
  \node[below right of=QAB] (Q2){$\literal{q_2}$};
  \path
    (Q)
      edge node {$\tau$} (QAB)
    (QAB)
      edge node[swap] {$\literal{a}\vphantom{\literal{b}}$} (Q1)
      edge node {$\literal{b}$} (Q2);
\end{tikzpicture}
```

Example system $\system_\literal{PQ}$.
::::

The program described by the transitions from $\literal{P}$ chooses nondeterministically during a $τ$-step between two options and then offers only *either* $\literal a$ *or* $\literal b$.
The program of $\literal{Q}$, on the other hand, performs a $τ$-step and then offers the choice between options $\literal a$ and $\literal b$ to the environment.
:::

There are two things one might wonder about @exm-ts:

1. Should one care about nondeterminism in programs?
  @sec-ccs shows how nondeterminism arises naturally in concurrent programs.
  And, of course, many specifications leave *undefind behavior*.
2. Should one consider $\literal P$ and $\literal Q$ equivalent?
  This heavily depends.
  Section [-@sec-behavioral-eq] will introduce a notion of equivalence under which the two are equivalent and one under which they differ.

::: {#rem-tau}
#### A note on $τ$

The action $τ$ (the Greek letter “tau”) will stand for *internal behavior* in later chapters and receive special treatment in @sec-weak-spectrum.
For the scope of this chapter and the following three, $τ$ is an action like every other.

Generally, this thesis aims to be consistent with notation and naming in surrounding literature.
<!--But people who have been exposed to fewer compiler classes and semantics literature often find all the greek letters daunting.
Where there are different options, we usually prefer the less-greek one.
After all, everything this thesis is about is simple, in a sense.-->
For the internal action, the whole field has converged to $τ$ in italics---so, we will run with this.
Otherwise, we follow the convention to write literals and constant names in $\textsf{sans-serif}$ and variables in $\textit{italics}$.
:::

\bigskip

### Calculus of Communicating Systems {#sec-ccs}

To talk about programs in this thesis, we use Milner's [-@milner1980ccs] *Calculus of Communicating Systems* (CCS), which---together with other great contributions---earned him the Turing award.
It is a tiny concurrent programming language that fits in your pocket, and can be properly described mathematically!^[
  To those not familiar with CCS:
  The following exposition of CCS is quite condensed.
  Gentler introduction can be found in textbooks like @milner1989comcon or @ails2007reactiveSystems and in the *interactive learning experience* <https://book.pseuco.com/>.
]

::: {#def-ccs}
#### Syntax of $\ccs$

Let $\ccschannels$ be a set of channel names, and $\ccsnames$ a set of process names.
Then, $\ccs$ is the set of processes given by the following grammar:^[
  To those familiar with CCS dialects:
  For the examples of the thesis, a simple CCS variant without value passing and relabeling suffices.
]
$$
\begin{array}{cllr}
  P \grammardef
  & \ccsprefix{c} P & \quad\text{with } c ∈ \ccschannels &
      \text{“input action prefix”} \\
  & \ccsprefix{\coaction c} P & \quad\text{with } c ∈ \ccschannels &
      \text{“output action prefix”} \\
  & \ccsprefix{τ} P & &
      \text{“internal action”} \\
  & \ccsnull & &
      \text{“null process”} \\
  & X & \quad\text{with } X ∈ \ccsnames &
      \text{“recursion”} \\
  & P \ccschoice P & &
      \text{“choice”} \\
  & P \, \ccspar \, P & &
      \text{“parallel composition”} \\
  & P \, \ccsrestrict A & \quad\text{with } A ⊆ \ccschannels &
      \text{“restriction”}
\end{array}
$$
Intuitively, input action $c$ represents receiving and output action $\coaction c$ expresses sending on channel $c \in \ccschannels$.
A pair of input and output can “react” in a communication situation and only become internal activity $τ$ in the view of the environment.
Taken together, CCS processes exhibit the actions $\ccsactions ≔ \ccschannels \cup \set{ \coaction{c} \mid c ∈ \ccschannels } \cup \set{τ}$. 

Each part of the syntax tree must end in a $\ccsnull$-process or recursion.
For brevity, we usually drop a terminal $\ccsnull$ when writing terms, e.g., just writing $\literal{ac}$ for $\ccsprefix{\literal{ac}} \ccsnull$.

We place parenthesis $(…)$ in terms where the syntax trees are otherwise ambiguous, but understand the choice operator $\ccschoice$ and the parallel operator $\ccspar$ to be associative.
This convention means that $(P_1 \ccschoice P_2) \ccschoice P_3$ and $P_1 \ccschoice (P_2 \ccschoice P_3)$ are representations of the same term in our view.
:::


::::: {#fig-philosopher-pic .column-margin}

{{< pic "img/philosophers.svg" "50%" >}}

Scenario of two philosophers needing a (second) fork to eat pasta.
:::::

::::: {#fig-isolated-philosopher .column-margin}

::::::: {.content-visible when-profile="foc"}
```tikz
\begin{tikzpicture}[auto,node distance=1.7cm]
  \node[] (Pa){$\literal{P_A}$};
  \node[right of=Pa] (a){$\literal{a}$};
  \node[right of=a] (Null){$\ccsnull$};
  \path[->]
    (Pa)
      edge node {$\literal{fork}$} (a)
    (a)
      edge node {$\literal{a}$} (Null);
\end{tikzpicture}
```
:::::::

::::::: {.content-visible unless-profile="foc"}
```tikz
\begin{tikzpicture}[auto,node distance=1.7cm]
  \node[] (Pa){$\literal{P_A}$};
  \node[below of=Pa] (a){$\literal{a}$};
  \node[below of=a] (Null){$\ccsnull$};
  \path[->]
    (Pa)
      edge node {$\literal{fork}$} (a)
    (a)
      edge node {$\literal{a}$} (Null);
\end{tikzpicture}
```
:::::::

Philosopher $\literal{P_A}$'s behavior on their own.
:::::

::: {#exm-ccs}
#### Concurrent philosophers

Following tradition, we express our examples in terms of philosophers who need forks to eat spaghetti.^[
  The philosopher meme is due to Dijkstra and @hoare1985csp. 
  Of course, you can just as well read the examples to be about computer programs that race for resources.]
Consider two philosophers $\literal{P_A}$ and $\literal{P_B}$ (from @fig-philosopher-pic) who want to grab a resource $\literal{fork}$, in order to eat, which we model as receiving communication.
We express $\literal{P_A}$ eating with $\literal{a}$ and $\literal{P_B}$ eating with $\literal{b}$.
The philosopher processes read:
$$
\begin{gathered}
  \literal{P_A} ≔ \ccsprefix{\literal{fork}} \ccsprefix{\literal a} \ccsnull \\
  \literal{P_B} ≔ \ccsprefix{\literal{fork}} \ccsprefix{\literal b} \ccsnull
\end{gathered}
$$
A transition system representation of $\literal{P_A}$'s behavior can be seen in @fig-isolated-philosopher.
Process $\literal P$ captures the whole scenario where the two philosophers compete for the fork using communication:
$$
  \literal P ≔ ( \ccsprefix{\coaction{\literal{fork}}} \ccsnull \ccspar \literal{P_A} \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}}
$$
The restriction $… \ccsrestrict \set{\literal{fork}}$ expresses that the $\literal{fork}$-channel can only be used for communication *within* the system.

As the $\coaction{\literal{fork}}$-message can be consumed by just one of the two philosophers, process $\literal P$ expresses exactly the program behavior seen in state $\literal P$ of @exm-ts.
A process matching $\literal Q$ will follow in @exm-deterministic-phil.
:::

The formal relationship between process terms of $\ccs$ and their transition system is established by the following semantics.

::: {#def-ccs-semantics}
#### CCS semantics

Given an assignment of names to processes, $\ccsasg \colon \ccsnames → \ccs$, the operational semantics ${\step{}_\ccs} ⊆ \ccs × \ccsactions × \ccs$ is defined inductively by the inference rules of @fig-ccs-rules.^[
  Such rules are read like this:
  “If we can derive the facts above the line, we may infer the relation below.”
  Rule $\mathrm{Pre}$, having no premises, serves as the only axiom of this inference system.
  @fig-deriving-transition shows how to stack such rules to infer that a certain step is possible for a process.
]

:::: {#fig-ccs-rules .column-body-outset}
$$
\inferrule[Pre]{
}{
  \ccsprefix{α} P \step{α}_\ccs P
}
\qquad
\inferrule[Rec]{
  P \step{α}_\ccs P' \qquad \ccsasg(X) = P
}{
  X \step{α}_\ccs P'
}
$$
$$
\inferrule[Choice_1]{
  P_1 \step{α}_\ccs P_1'
}{
  P_1 \ccschoice P_2 \step{α}_\ccs P_1'
}\qquad
\inferrule[Choice_2]{
  P_2 \step{α}_\ccs P_2'
}{
  P_1 \ccschoice P_2 \step{α}_\ccs P_2'
}
$$
$$
\inferrule[Par_1]{
  P_1 \step{α}_\ccs P_1'
}{
  P_1 \ccspar P_2 \step{α}_\ccs P_1' \ccspar P_2
}\qquad
\inferrule[Par_2]{
  P_2 \step{α}_\ccs P_2'
}{
  P_1 \ccspar P_2 \step{α}_\ccs P_1 \ccspar P_2'
}
$$
$$
\inferrule[Com_1]{
  P_1 \step{c}_\ccs P_1' \qquad
  P_2 \step{\coaction c}_\ccs P_2'
}{
  P_1 \ccspar P_2 \step{τ}_\ccs P_1' \ccspar P_2'
}\;
\inferrule[Com_2]{
  P_1 \step{\coaction c}_\ccs P_1' \qquad
  P_2 \step{c}_\ccs P_2'
}{
  P_1 \ccspar P_2 \step{τ}_\ccs P_1' \ccspar P_2'
}
$$
$$
\inferrule[Res]{
  P \step{α}_\ccs P' \qquad
  \nexists c \in A \ldotp α = c \lor α = \coaction{c}
}{
  P \ccsrestrict A \step{α}_\ccs P' \ccsrestrict A
}
$$

Inference rules defining $\step{}_\ccs$.
::::

A process $P ∈ \ccs$ now denotes a state within system $(\ccs, \ccsactions, \step{}_\ccs)$.
:::

So, when we were writing “$\literal{P_A} ≔ \ccsprefix{\literal{fork}} \ccsprefix{\literal a} \ccsnull$” above, this was actually to claim that we are talking about a CCS system where the value of $\ccsasg$ for the *process name* $\literal{P_A} \in \ccsnames$ is defined by $\ccsasg(\literal{P_A}) ≔ \ccsprefix{\literal{fork}} \ccsprefix{\literal a} \ccsnull$.
By the semantics, this also leads to the existence of a *state* $\literal{P_A}$ in the CCS transition system, and usually that is the entity we are interested in when defining a process.

Feel free to go ahead and check that the transitions of @exm-ts indeed match those that @def-ccs-semantics prescribes for $\literal{P}$ of @exm-ccs!
(For readability, @exm-ts, has shorter state names, however.)
For instance, the transition $\literal P \step{τ} \literal{p_a}$ in the CCS system of @exm-ts would be justified by the derivation in @fig-deriving-transition with $\literal{p_a} = ( \ccsnull \ccspar \literal a \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}}$.

::: {#fig-deriving-transition fig-pos="t" fig-env="figure*"}

```{=latex}
\begin{adjustbox}{max width=\linewidth, center, varwidth=16.5cm}
```

$$
\inferruleapp[Rec]{
  \hspace{-2em}
  \inferruleapp[Res]{
    \hspace{-2em}
    \inferruleapp[Com_2]{
    \hspace{-2em}
      \inferruleapp[Pre]{
        \vphantom{\stepnosmash{\coaction{\literal{fork}}}_\ccs}
      }{
        \coaction{\literal{fork}} \stepnosmash{\coaction{\literal{fork}}}_\ccs \ccsnull
      }
      \quad
      \inferruleapp[Par_1]{
        \hspace{-2em}
        \inferruleapp[Rec]{
          \hspace{-2em}
          \inferruleapp[Pre]{
          }{
            \ccsprefix{\literal{fork}} \literal a
            \stepnosmash{\literal{fork}}_\ccs
            \literal a
          }
          \qquad
          \begin{array}{c}
            \vphantom{\ccsasg\stepnosmash{\literal{fork}}_\ccs} \\
            \vphantom{\stepnosmash{\literal{fork}}_\ccs}
            \ccsasg(\literal{P_A}) = \ccsprefix{\literal{fork}} \literal{a}
          \end{array}
        }{
          \literal{P_A} \stepnosmash{\literal{fork}}_\ccs \literal a
        }
      }{
        \literal{P_A} \ccspar \literal{P_B} \stepnosmash{\literal{fork}}_\ccs \literal a \ccspar \literal{P_B}
      }
    }{
      \coaction{\literal{fork}} \ccspar \literal{P_A} \ccspar \literal{P_B}
      \stepnosmash{τ}_\ccs
      \ccsnull \ccspar \literal a \ccspar \literal{P_B}
    }
    \hspace{-1em}
    \begin{matrix}
      \vphantom{\stepnosmash{\coaction{\literal{fork}}}_\ccs}\\
      τ \notin \set{\literal{fork}, \coaction{\literal{fork}}}
    \end{matrix}
  }{
    ( \coaction{\literal{fork}} \ccspar \literal{P_A} \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}}
    \stepnosmash{τ}_\ccs
    ( \ccsnull \ccspar \literal a \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}}
  }
  \hspace{-1em}
  \begin{matrix}
    \vphantom{\stepnosmash{\coaction{\literal{fork}}}_\ccs}\\
    \ccsasg(\literal P) = ( \coaction{\literal{fork}} \ccspar \literal{P_A} \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}}
  \end{matrix}
}{
  \literal P \stepnosmash{τ}_\ccs ( \ccsnull \ccspar \literal a \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}}
}
$$

```{=latex}
\end{adjustbox}
```

Deriving CCS transitions due to communication.
:::

Therefore, after one step from $\literal{P}$, the (internal) $\literal{fork}$ has been consumed, and only one philosopher may eat.
From the outside, this appears as nondeterminism of the system.

Nondeterminism as in $\literal P$ of @exm-ts can be understood as a natural phenomenon in models with concurrency.
The model leaves unspecified which of two processes will consume an internal resource and, to the outsider, it is transparent which one took the resource until they communicate.
There are other ways how nondeterminism plays a crucial role in models, for instance, as consequence of abstraction or of parts that are left open in specifications.

The second process $\literal Q$ of @exm-ts can be understood as a *deterministic* sibling of&nbsp;$\literal P$.

::: {#exm-deterministic-phil}
#### Deterministic philosophers

A process matching the transitions from $\literal Q$ in @exm-ts would be the following, where the philosophers take the fork as a team and then let the environment choose who of them eats:
$$
\literal Q ≔ (\ccsprefix{\coaction{\literal{fork}}} \ccsnull \ccspar \ccsprefix{\literal{fork}} ( \ccsprefix{\literal{a}} \ccsnull \ccschoice \ccsprefix{\literal{b}} \ccsnull )) \ccsrestrict \set{\literal{fork}}.
$$
:::

But are $\literal{P}$ and $\literal{Q}$ *equivalent*?

## Behavioral Equivalences {#sec-behavioral-eq}

A behavioral equivalence formally defines when to consider two processes (or states, or programs) as *equivalent*.
Evidently, there are different ways of choosing such a notion of equivalence.
Also, sometimes we are interested in a behavioral *preorder*, for instance, as a way of saying that a program does “less than” what some specification allows.
Such a relationship is often also called *refinement* or *inclusion*, but we will go with *preorder*.

This section quickly introduces the most common representatives of behavioral equivalences:
Trace equivalence (and preorder), simulation equivalence (and preorder), and bisimilarity.
We will then observe that the notions themselves can be compared in a hierarchy of equivalences.

### Trace Equivalence

Every computer science curriculum features automata and their languages sometime at the beginning.
Accordingly, comparing two programs in terms of the sequences of input/output events they might expose is a natural starting point to talk about behavioral equivalences.
Such sequences of actions are referred to as *traces*.

::: {#def-traces}
#### Traces

The set of traces of a state $\traces{p} \subseteq \actions^*$ is inductively defined as

- $\emptyword ∈ \traces{p}$,^[We denote the empty word by $\emptyword$.]
- $α {\vec w} ∈ \traces{p}$ if there is $p'$ with $p \step α p'$ and $\vec w ∈ \traces{p'}$.{{<isb abbreviation Labeled_Transition_Systems lts.traces>}}
:::

::: {#def-trace-eq}
#### Trace equivalence

Two states $p$ and $q$ are considered *trace-equivalent*, written $p \beq{T} q$, if $\traces{p} = \traces{q}$.{{<isb abbreviation Strong_Equivalences lts.trace_equivalent>}}

States are *trace-preordered*, $p \bpreord{T} q$, if $\traces{p} ⊆ \traces{q}$.{{<isb definition Strong_Equivalences lts.trace_preordered>}}
:::

::: {#exm-phil-traces}
The traces for the processes of @exm-ts would be $\traces{\literal{P}} = \set{\emptyword, τ, τ\literal{a}, τ\literal{b}} = \traces{\literal Q}$. Consequently, $\literal P$ and $\literal Q$ are trace-equivalent, $\literal P \beq{T} \literal Q$.

As $\traces{\literal{p_a}} = \set{\emptyword, \literal{a}} ⊆ \set{\emptyword, \literal{a}, \literal{b}} = \traces{\literal{q_{ab}}}$, $\literal{p_a}$ is trace-preordered to $\literal{q_{ab}}$, $\literal{p_a} \bpreord{T} \literal{q_{ab}}$.
This ordering is strict, that is, $\literal{q_{ab}} \nbpreord{T} \literal{p_a}$, due to $\literal{b} ∈ \traces{\literal{q_{ab}}}$ but $\literal{b} \notin \traces{\literal{p_a}}$.
We could say that trace $\literal{b}$ constitutes a *difference* between $\literal{q_{ab}}$ and $\literal{p_a}$.
:::

::: {#prp-trace-eq-rel}
Trace preorder $\bpreord{T}$ is indeed a preorder (i.e., transitive and reflexive){{<isb lemma Strong_Equivalences lts.trace_preorder_transitive>}} and trace equivalence $\beq{T}$ is indeed an equivalence relation{{<isb lemma Strong_Equivalences lts.trace_equivalence_equiv>}} (i.e., transitive, reflexive, and moreover symmetric).^[
  This thesis states many facts, only linking to their proof.
  In this case, proofs can be found in the Isabelle/HOL formalization, indicated by ![Isabelle icon](img/isabelle.png){height=0.9em}.
]
:::
<!-- proof
The properties carry over directly from $⊆$ and $=$ on sets of $\traces{\cdot}$. -->

Trace equivalence (and preorder) give straightforward *denotational semantics* to programs:
The sets of traces they might expose.
For many formal languages, these mathematical objects can be constructed directly from the expressions of the language.
With the idea that the program text “denotes” its possible executions, the set of traces is called a “denotation” in this context.
CCS, as we use it, follows another approach to semantics, namely the one of “operational semantics,” where the meaning of a program is in how it might interact.

There are several reasons why computer scientists did not content themselves with trace equivalence when studying interactive systems.
The core argument is that, in this context, one usually does not want to consider processes like $\literal{P}$ and $\literal{Q}$ to be equivalent:
The two might interact differently with an environment.

:::{#exm-philosopher-environment}
#### Live lecture

Consider a context in which $\literal{A}$ actually does not want to eat and the event of $\literal{B}$ eating is followed by $\literal{B}$ giving a live lecture:
$$
(\dots \ccspar \ccsprefix{\coaction{\literal{b}}}\ccsprefix{\coaction{\literal{lecture}}} \ccsnull) \ccsrestrict \set{\literal{a}, \literal{b}}
$$
If we insert $\literal{Q}$ for the “$\dots$” in this context, the choice after the collective $\literal{fork}$-acquisition is resolved to the $\literal{B}$-path.
So the overall system chooses for $\literal{B}$ to eat, and the lecture happens:
$$
(\literal{Q} \ccspar \ccsprefix{\coaction{\literal{b}}}\ccsprefix{\coaction{\literal{lecture}}} \ccsnull) \ccsrestrict \set{\literal{a}, \literal{b}} \step{\tau} \cdot \step{\tau} \cdot \step{\coaction{\literal{lecture}}}
(\ccsnull \ccspar \ccsnull) \ccsrestrict \set{\literal{a}, \literal{b}}
$$
With $\literal{P}$, an analogous path is possible.
But there is, moreover, a possibility of $\literal{A}$ obtaining the fork, which prevents $\literal{B}$ from eating.
There, the system can end up deadlocked with no lecture:
$$
(\literal{P} \ccspar \ccsprefix{\coaction{\literal{b}}}\ccsprefix{\coaction{\literal{lecture}}} \ccsnull) \ccsrestrict \set{\literal{a}, \literal{b}}
\step{\tau} 
((\ccsnull \ccspar \literal a \ccspar \literal{P_B} ) \ccsrestrict \set{\literal{fork}} \ccspar \ccsprefix{\coaction{\literal{b}}}\ccsprefix{\coaction{\literal{lecture}}} \ccsnull) \ccsrestrict \set{\literal{a}, \literal{b}}
\nostep{}
$$
So, if $\literal{B}$'s teaching actually happening matters to us, we might say that scenario $\literal{P}$ and $\literal{Q}$ are not quite equivalent.^[
  Traditionally, this feature of trace equivalence is often framed in terms of vending machines.
  On <https://book.pseuco.com/#/interactive/trace-equivalent-vending-machines>, you can play through a comparable scenario of ordering drinks where *you are the environment*.
]
:::

Computer scientists might not all care about philosophy lectures.
But they care about the *liveness* of interactive programs.
Therefore, they have invented many program equivalences that pay more attention to *possibilities coming and going*.
The most prominent ones are the topic of the next subsection.

### Similarity and Bisimilarity

The other big approach to behavioral equivalence of programs is the one of relating parts of their state spaces to one-another.
The idea here is to identify which states of one program can be used to *simulate* the behavior of the other.

::: {#def-simulation}
#### Simulation

A relation on states, $\rel R ⊆ \states × \states$, is called a *simulation* if, for each $(p, q) ∈ \rel R$ and $α ∈ \actions$ with $p \step a p'$ there is a $q'$ with $q \step α q'$ and $(p', q') ∈ \rel R$.{{<isb definition Strong_Equivalences lts.simulation>}}
:::

::: {#def-bisimilarity}
#### (Bi-)similarity

Simulation preorder, simulation equivalence and bisimilarity are defined as follows:

- $p$ is *simulated by* $q$, $p \bpreord{S} q$, iff there is a simulation $\rel R$ with $(p, q) ∈ \rel R$.{{<isb definition Strong_Equivalences lts.simulated_by>}}
- $p$ is *similar* to $q$, $p \beq{S} q$, iff $p \bpreord{S} q$ and $q \bpreord{S} p$.{{<isb abbreviation Strong_Equivalences lts.similar>}}
- $p$ is *bisimilar* to $q$, $p \beq{B} q$, iff there is a *symmetric* simulation $\rel R$ (i.e. $\rel R = \inverse{\rel R}$) with $(p, q) ∈ \rel R$.{{<isb definition Strong_Equivalences lts.bisimilar>}}
:::

We also call a symmetric simulation *bisimulation* for short.^[
  Other authors use a weaker definition, namely, that $\rel R$ is a bisimulation if $\rel{R}$ and $\inverse{\rel{R}}$ are simulations.
  Both definitions lead to the characterization of the same notion of bisimilarity.
  The symmetric version works better for our purpose of establishing a nice link to logics and games.
]
Canceled symbols of relations refer to their negations, for instance, $p \nbpreord{S} q$ iff there is *no* simulation $\rel R$ with $(p, q) ∈ \rel R$.

::: {#exm-phil-sim}
#### Philosophical simulations

The following relations are simulations on the system of @exm-ts:

- the empty relation $\rel R_\varnothing ≔ \varnothing$;
- the identity relation $\rel R_\mathrm{id} ≔ \identity{\set{\literal P, \literal{p_a}, \literal{p_b}, \literal{p_1}, \literal{p_2}, \literal Q, \literal{q_{ab}}, \literal{q_1}, \literal{q_2}}} = \set{(\literal P, \literal P),\allowbreak (\literal{p_a}, \literal{p_a}),\allowbreak (\literal{p_b}, \literal{p_b}), (\literal{p_1}, \literal{p_1}),\allowbreak (\literal{p_2}, \literal{p_2}), (\literal Q, \literal Q), (\literal{q_{ab}}, \literal{q_{ab}}), \allowbreak(\literal{q_1}, \literal{q_1}), (\literal{q_2}, \literal{q_2})}$;
- the universal relation between all terminal states  
  $\rel R_\mathrm{term} ≔ \set{\literal{p_1}, \literal{p_2}, \literal{q_1}, \literal{q_2}} \times \set{\literal{p_1}, \literal{p_2}, \literal{q_1}, \literal{q_2}}$,
- more generally, the relation from terminal states to all other states: $\rel R_\mathrm{up} ≔ \set{\literal{p_1}, \literal{p_2}, \literal{q_1}, \literal{q_2}} × \states$;
- a minimal simulation for $\literal P$ and $\literal Q$:  
  $\rel R_\literal{PQ} ≔ \set{(\literal{P}, \literal{Q}), (\literal{p_a}, \literal{q_{ab}}), (\literal{p_b}, \literal{q_{ab}}), (\literal{p_1}, \literal{q_1}), (\literal{p_2}, \literal{q_2})}$;
- and the combination of the above $\rel R_\mathrm{big} ≔ \rel R_\mathrm{id} ∪ \rel R_\mathrm{term} ∪ \rel R_\mathrm{up} ∪ \rel R_\literal{PQ}$.

The simulation $\rel R_\literal{PQ}$ shows that $\literal P \bpreord{S} \literal Q$.

However, there is no simulation that preorders $\literal Q$ to $\literal P$, as there is no way to simulate the transition $\literal Q \step{τ} \literal{q_{ab}}$ from $\literal P$ for lack of a successor that allows $\literal a$ *and* $\literal b$ as does $\literal{q_{ab}}$.
(In @sec-hml, we will discuss how to capture such differences more formally.)

Thus, $\literal Q \nbpreord{S} \literal P$, and $\literal P \nbeq{S} \literal Q$. Moreover, there cannot be a symmetric simulation, $\literal P \nbeq{B} \literal Q$.
:::

::: {#prp-sim-eq-rel}
The simulation preorder $\bpreord{S}$ is indeed a preorder{{<isb lemma Strong_Equivalences lts.simulation_preorder_transitive>}}, and $\beq{S}$ and $\beq{B}$ are equivalences.{{<isb lemma Strong_Equivalences lts.bisimilarity_equiv>}}
:::
<!-- Too trivial.
::: proof
1. Reflexivity of $\bpreord{S}$, $\beq{S}$ and $\beq{B}$:<br> $\identity{\states}$ is a (symmetric) simulation on each transition system.
2. Transitivity of $\bpreord{S}$:<br>
  If $\rel R_1$ and $\rel R_2$ are simulations, then the composition $\rel R_1 \rel R_2$ too is a simulation.
  This also establishes transitivity of $\beq{S}$.
  Moreover, that simulation $\rel R_1$ and $\rel R_2$ imply the composition $\rel R_1 \cup \rel R_2$ to be a simulation, allows to combine symmetric simulations to prove transitivity of $\beq{B}$.
3. Symmetry of $\beq{S}:$ By definition.
4. Symmetry of $\beq{B}$:<br>
  $p \beq{B} q$ implies there is a symmetric simulation $\rel R$ with $(p,q) ∈ \rel R$.
  As $\rel R = \inverse{\rel R}$, this implies $(q,p) ∈ \rel R$ and thus $q \beq{B} p$.
  \qedhere
:::
-->

@exm-phil-sim shows that similarity and bisimilarity are not implied by trace equivalence.
Still, the notions are connected, which is commonly referred to as bisimilarity being “stronger” than trace equivalence.

### Equivalence Hierarchies {#sec-hierarchy-equivalences}

Bisimilarity, similarity and trace equivalence form a small hierarchy of equivalences in the sense that they imply one-another in one direction, but not in the other.
Let us quickly make this formal:

:::: {#fig-core-hierarchy .column-margin}
```tikz
\begin{tikzpicture}[auto,node distance=1.5cm,
  notion/.style={minimum width=3cm, minimum height=.8cm, rectangle,align=center,rounded corners}]
  \node[notion, text=gray] (GI){Graph isomorphism};
  \node[notion, below of=GI] (B){Bisimilarity};
  \node[notion, below of=B] (S){Similarity};
  \node[notion, below of=S] (T){Trace equivalence};
  \path[->]
    (GI)
      edge[dashed] node {} (B)
    (B)
      edge node {} (S)
    (S)
      edge node {} (T);
\end{tikzpicture}
```

Core hierarchy of equivalences.  
(Arrows mean implication.)
::::

::: {#lem-bisim-bisim}
The relation $\beq{B}$ is itself a symmetric simulation.{{<isb lemma Strong_Equivalences lts.bisim_bisim>}}
:::

::: {#cor-bisim-impl-sim}
If $p \beq{B} q$, then $p \beq{S} q$.{{<isb lemma Strong_Equivalences lts.bisim_bisim>}}
:::

::: {#lem-sim-impl-traces}
If $p \bpreord{S} q$, then $p \bpreord{T} q$.{{<isb lemma Strong_Equivalences lts.sim_implies_trace_preord>}}
(Consequently, $p \beq{S} q$ also implies $p \beq{T} q$.{{<isb lemma Strong_Equivalences lts.sim_eq_implies_trace_eq>}})
:::

We also have seen with @exm-phil-sim that this hierarchy of implications (visualized in @fig-core-hierarchy) is strict between trace and simulation preorder in the sense that there exist $p,q$ with $p \bpreord{T} q$ but not $p \bpreord{S} q$.
The hierarchy also is strict between similarity and bisimilarity as the following example shows.

::::{#wrapper-fig-bisim-sim-ts}
```tikz
\begin{tikzpicture}[auto,node distance=2cm]
  \node[] (q0){$\literal{T}$};
  \node[below left of=q0] (qAB){$\literal{t_{ab}}$};
  \node[below left of=qAB] (q1){$\literal{t_{1}}$};
  \node[below right of=qAB] (q2){$\literal{t_{2}}$};
  \node[below right of=q0] (q3){${\huge{\trollface}}$};
  \path[->]
    (q0)
      edge[swap] node {$\tau$} (qAB)
      edge node {$\tau$} (q3)
    (qAB)
      edge[swap] node {$\literal{a}$} (q1)
      edge node {$\literal{b}$} (q2);
\end{tikzpicture}
```
::::

:::: {#wrapper-fig-iso-ts}
```tikz
\begin{tikzpicture}[auto,node distance=2cm]
  \node[] (pEven){$\literal{p_{even}}$};
  \node[below of=pEven] (pOdd){$\literal{p_{odd}}$};
  \path[->]
    (pEven)
      edge[swap, bend right=15] node {$\tau$} (pOdd)
    (pOdd)
      edge[swap, bend right=15] node {$\tau$} (pEven);
\end{tikzpicture}
```
::::

::: {#exm-bisim-sim}
#### Trolled philosophers

Let us extend $\literal{Q}$ of @exm-deterministic-phil to include a troll process (highlighted in blue) that might consume the $\literal{fork}$ and then do nothing:
$$
\literal {T} ≔ (\coaction{\literal{fork}} \ccspar \mathhl{\literal{fork}} \ccspar \ccsprefix{\literal{fork}} ( \literal{a} \ccschoice \literal{b} )) \ccsrestrict \set{\literal{fork}}.
$$
This adds another deadlock state to the transition system, seen in @fig-bisim-sim-ts.

:::: {.content-visible unless-profile="foc"}
::::: {#fig-bisim-sim-ts .column-margin}
{{< contents wrapper-fig-bisim-sim-ts >}}

Example with new deadlock.
:::::
::::

With respect to similarity, this change is invisible, that is, $\literal Q \beq{S} \literal{T}$.
(Formal argument: The relation $\set{
  (\literal{Q}, \literal{T}),
  (\literal{T}, \literal{Q}),
  (\literal{q_{ab}}, \literal{t_{ab}}),
  (\literal{t_{ab}}, \literal{q_{ab}}),
  (\troll, \literal{q_{ab}})
} \cup
\set{ \literal{q_1}, \literal{q_2}, \literal{t_1}, \literal{t_2}, \troll}
\times \set{ \literal{q_1}, \literal{q_2}, \literal{t_1}, \literal{t_2}, \troll}$ is a simulation.)

However, to bisimilarity, $\literal{T} \step{τ} \troll$ constitutes a difference.
There cannot be a *symmetric* simulation handling this transition as $\literal{Q}$ has no deadlocked successors.
Thus $\literal Q \nbeq{B} \literal{T}$.
:::

::: {.content-visible when-profile="foc"}
```{=latex}
\begin{figure}[t]

\begin{minipage}[b]{0.48\textwidth}
```

:::: {#fig-bisim-sim-ts fig-pos="H"}
{{< contents wrapper-fig-bisim-sim-ts >}}

Variant of $\literal{Q}$ with a new deadlock.
::::

```{=latex}
\end{minipage}
\hfill
\begin{minipage}[b]{0.48\textwidth}
```

:::: {#fig-iso-ts fig-pos="H"}
{{< contents wrapper-fig-iso-ts >}}

Transition system with an isomorphic cycle.
::::

```{=latex}
\end{minipage}
\end{figure}
```
:::

The equivalences we have discussed so far could also be understood as abstractions of an even finer equivalence, namely graph isomorphism:

::: {#def-graph-isomorphism}
#### Graph isomorphism

A bijective function $f \colon \states \to \states$ is called a *graph isomorphism* on a transition system if, for all $p,p', α$, the transition $p \step{α} p'$ exists if and only if the transition $f(p) \step{α} f(p')$ exists.{{<isb definition Strong_Equivalences lts.isomorphism>}}

Two states $p$ and $q$ are considered *graph-isomorphism-equivalent*, $p \beq{ISO} q$, iff there is a graph isomorphism $f$ with $f(p) = q$.{{<isb definition Strong_Equivalences lts.is_isomorphic_to>}}
:::

::: {#exm-graph-isomorphism}
Consider the transition system in @fig-iso-ts. $\literal{p_{even}} \beq{ISO} \literal{p_{odd}}$ because $f ≔ \set{\literal{p_{even}} \mapsto \literal{p_{odd}}, \literal{p_{odd}} \mapsto \literal{p_{even}}}$ is a graph isomorphism.

:::: {.content-visible unless-profile="foc"}
::::: {#fig-iso-ts .column-margin fig-pos="H"}
{{< contents wrapper-fig-iso-ts >}}

Transition system with an isomorphic cycle.
:::::
::::

:::

::: {#lem-iso-impl-bisim}
The relation $\beq{ISO}$ is itself a symmetric simulation and thus $p \beq{ISO} q$ implies $p \beq{B} q$.{{<isb lemma Strong_Equivalences lts.iso_implies_bisim>}}
:::

Once again, the hierarchy is strict because of bisimilarity being less restricted in the matching of equivalent states.

::: {#exm-iso-vs-bisim}
#### Graph isomorphism counts too much

Consider the processes $\literal{P_1} ≔ (\coaction{\literal{fork}} \ccspar \literal{fork}) \ccsrestrict \set{\literal{fork}}$ and $\literal{P_2} ≔ (\coaction{\literal{fork}} \ccspar \literal{fork} \ccspar \literal{fork}) \ccsrestrict \set{\literal{fork}}$.
$\literal{P_1}$ can transition to $(\ccsnull \ccspar \ccsnull) \ccsrestrict \set{\literal{fork}}$, while $\literal{P_2}$ has two options, namely $(\ccsnull \ccspar \ccsnull \ccspar \literal{fork}) \ccsrestrict \set{\literal{fork}}$ and $(\ccsnull \ccspar \literal{fork} \ccspar \ccsnull) \ccsrestrict \set{\literal{fork}}$.
All three reachable processes are deadlocks and thus isomorphic.
But $\literal{P_1} \nbeq{ISO} \literal{P_2}$ because no bijection can connect the one successor of $\literal{P_1}$ and the two of $\literal{P_2}$.
However, $\literal{P_1} \beq{B} \literal{P_2}$, as bisimilarity is more relaxed.
:::

Graph isomorphism is the strongest equivalence, we have discussed so far.
But stronger needs not be better.

### Congruences

One of the prime quality criteria for behavioral equivalences is whether they form *congruences* with respect to fitting semantics or other important transformations.
A congruence relates mathematical objects that can stand in for one-another in certain contexts, which, for instance, allows term rewriting.
The concept is closely linked to another core notion of mathematics: monotonicity.

::: {#def-monotonic}
#### Monotonicity and congruence

An $n$-ary function $f \colon B_1 \times \dots \times B_n \to C$ is called *monotonic* with respect to a family of preorders $(B_k, \leq_k)$ and $(C, \leq)$ iff, for all $b \in B_1 \times \dots \times B_n$ and $b' \in B_1 \times \dots \times B_n$, it is the case that $b^{\vphantom{\prime}}_k \leq^{\vphantom{\prime}}_k b'_k$ for all $k \leq n$ implies that $f(b) \leq f(b')$.
We will usually encounter settings where all components use the same order ${(B_1, \leq_1)} = \cdots = {(B_n, \leq_n)} = {(C, \leq)}$.

The relation $\leq$ is then referred to as a *precongruence* for $f$.
If $\leq$ moreover is symmetric (and thus an equivalence relation), then $\leq$ is called a *congruence* for $f$.
:::

::: {#exm-congruence-oddity}
#### Parity as congruence
As a standard example for a congruence, consider the equivalence relation of equally odd numbers:
$${\sim_\literal{odd}} ≔ \set{(m,n) \in \nats \times \nats \mid m \bmod 2 = n \bmod 2}.$$
For instance, $1 \sim_\literal{odd} 3$ and $0 \sim_\literal{odd} 42$, but not $42 \sim_\literal{odd} 23$.

$\sim_\literal{odd}$ is a congruence for addition and multiplication.
For instance, the sum of two odd numbers will always be even; the product of two odd numbers, will always be odd.

But $\sim_\literal{odd}$ is no congruence for integer division.
For instance, $2 \sim_\literal{odd} 4$, but $2 / 2 = 1 \not\sim_\literal{odd} 2 = 4 / 2$.
:::

::: {#prp-ccs-congruences}
Trace equivalence and bisimilarity on the CCS transition system (@def-ccs-semantics)
are congruences for the operators of CCS (@def-ccs).^[
  For a generic proof of the congruence properties of trace equivalence, bisimilarity, and most other notions of the equivalence spectrum, see @gfm2020congruenceOperator.
]
:::
<!--proof
This is a well-established fact.

As an example, let us prove the congruence property for choice, $\ccschoice$, on bisimilarity, $\beq{B}$.
For any CCS context, we assume $P \beq{B} R$ and $Q \beq{B} T$.
We have to show that $P \ccschoice Q \beq{B} R \ccschoice T$,
that is due to symmetry, that for any $\alpha$ with $P \ccschoice Q \step{\alpha}_\ccs \mathit{PQ}'$ there is $\mathit{RT}'$ such that $R \ccschoice T \step{\alpha}_\ccs \mathit{RT}'$ and $\mathit{PQ}' \beq{B} \mathit{RT}'$.
By the semantics of CCS, the first step must be either due to $P \step{\alpha}_\ccs \mathit{PQ}'$ or, analogously, $Q \step{\alpha}_\ccs \mathit{PQ}'$.
Without loss of generality, we only consider $P \step{\alpha}_\ccs \mathit{PQ}'$.
Due to $P \beq{B} R$, this step implies some $R'$ with $R \step{\alpha}_\ccs R'$ and $\mathit{PQ}' \beq{B} R'$.
As $R \ccschoice T \step{\alpha}_\ccs R'$, we can take this $R'$ to prove our goal.
-->

The nice thing about congruences is that we can use them to *calculate with terms*, as is common in mathematics.

Graph isomorphism fails to be a congruence for CCS operators.
For instance, consider $\ccsprefix{\literal{a}} (\ccsnull \ccspar \ccsnull) \beq{ISO} \ccsprefix{\literal{a}} \ccsnull$.
But if one inserts the two terms in a choice context, the results differ with respect to isomorphism:
$\ccsprefix{\literal{a}} \ccsnull + \ccsprefix{\literal{a}} (\ccsnull \ccspar \ccsnull) \nbeq{ISO} \ccsprefix{\literal{a}}\ccsnull + \ccsprefix{\literal{a}}\ccsnull \beq{ISO} \ccsprefix{\literal{a}} \ccsnull$. 

<!-- too complicated!

We could establish equivalences like the following:

$$
\begin{array}{rrcl}
(1) & \ccsprefix{\coaction{a}} P \ccspar \ccsprefix{a} Q & \beq{B}
    & \ccsprefix{\coaction{a}} (P \ccspar \ccsprefix{a} Q) \ccschoice \ccsprefix{a} (\ccsprefix{\coaction{a}} P \ccspar Q) \ccschoice \ccsprefix{\tau} (P \ccspar Q) \\
(2) & (\ccsprefix{a} P \ccschoice \ccsprefix{b} Q) \ccsrestrict A & \beq{B} & \ccsprefix{a} P \ccsrestrict A \ccschoice \ccsprefix{b}Q \ccsrestrict A \\
(3) & (\ccsprefix{a} P) \ccsrestrict \set{a} & \beq{B} & 0 \\
(4) & \ccsnull \ccschoice P & \beq{B} & P \\
(5) & \ccsnull \ccspar P & \beq{B} & P
\end{array}
$$

$$
\begin{array}{rcl}
&  & (\coaction{\literal{fork}} \ccspar \ccsprefix{\literal{fork} \ccspar \literal{fork}} ( \literal{a} \ccschoice \literal{b} )) \ccsrestrict \set{\literal{fork}} \\
& \beq{B} &
  ( \ccsprefix{\tau} (\ccsnull \ccspar \ccsnull \ccspar \ccsprefix{\literal{fork}} (\literal{a} \ccschoice \literal{b})) \ccschoice \ccsprefix{\tau} ( \ccsnull \ccspar \literal{fork} \ccspar \literal{a} \ccschoice \literal{b} )) \ccsrestrict \set{\literal{fork}}
\end{array}
$$
-->

By now, we have encountered some behavioral equivalences.
Both, bisimilarity and trace equivalence make for fine congruences that allow calculations on process-algebraic expressions of $\ccs$.
Which one to choose?
That there is no definitive answer is a root cause of this thesis.

::: {#rem-csp-ccs}
#### Origins of linear time and branching time

This thesis is a consequence of the classic idea that behavioral equivalences form a *spectrum* between linear-time notions and branching-time notions.
This hierarchy corresponds to “how much” calculation is allowed on algebraic expressions of processes.

Bisimilarity is the prototypical *branching-time* equivalence: every decision during execution counts.
Trace equivalence is the prototypical *linear-time* notion: only sequences of actions count.
Therefore, more can be seen as equivalent than in bisimilarity.

In the concurrency theory community, two prototypical *process algebras* stand for this spread:
CCS for bisimilarity and branching time,
and CSP for trace equivalence and linear-time.
CSP (“Communicating Sequential Processes”) is due to Hoare, another Turing award winner.

@hoare1985csp [§ 7.4.1] summarizes the opposing design philosophies between CCS and CSP as follows:

> [...] CCS is intended to serve as a framework for a family of models, each of which may make more identifications than CCS but cannot make less.
> To avoid restricting the range of models, CCS makes only those identifications which seem absolutely essential.
> In the mathematical model of [CSP] we have pursued exactly the opposite goal—we have made as many identifications as possible, preserving only the most essential distinctions.
> We have therefore a far richer set of algebraic laws.

The first comprehensive study on the correspondence between the hierarchy of equivalences and algebraic laws has been dubbed “linear-time–branching-time spectrum” by @glabbeek1990ltbt1.^[
  Further historical remarks on the spectrum are assembled by @erph2013unfyingLTBTS, incidentally also quoting from @hoare1985csp.
]

Historically, therefore, this thesis originates from the tension between the works of two Turing award winners: Milner's CCS and Hoare's CSP.
Or, as @hoare2006whyEverCSP puts it:
“It seems that CCS and CSP occupy extreme ends of almost every spectrum.”

But do not worry---although our research question is a consequence of the possibility to come up with various process algebras, this thesis will stick to only one, CCS. 
<!--
> Of all subsequently explored process calculi, CCS defined a minimal set of primitives and operators, with a minimal set of equations relating them, whereas CSP has explored a wide range of concepts that have proved useful in concurrent system design.
-->
:::

\bigskip

### Quotient Systems and Minimizations

One of the prime applications of behavioral equivalences is to battle the *state space explosion problem*:
The transition systems of parallel processes quickly grow in size, usually exponentially with regard to the number of communication participants.
But many of the states tend to be equivalent in behavior, and can be treated *as one* with their equals.
Such *minimization* enables the handling of vastly bigger input models.

::: {#exm-bisim-minimization}
#### Trolled philosophers, minimized

In @exm-bisim-sim of “trolled philosophers,” all terminal states are bisimilar, $\literal{t_1} \beq{B} \literal{t_2} \beq{B} \troll$.
We can thus merge them into one state $\smash{\troll}^\literal{m}$ as depicted in @fig-bisim-min-ts, without affecting the behavioral properties of the other states with respect to bisimilarity, that is, $\literal{t_{ab}} \beq{B} \literal{t_{ab}^m}$ and $\literal{T} \beq{B} \literal{T^m}$.

:::: {#fig-bisim-min-ts .column-margin}
```tikz
\begin{tikzpicture}[auto,node distance=2cm]
  \node[] (q0){$\literal{T^m}$};
  \node[below left of=q0] (qAB){$\literal{t^m_{ab}}$};
  \node[below right of=qAB] (q123){$\literal{\large{\trollface}^m}$};
  \path[->]
    (q0)
      edge[swap, bend right=10] node {$\tau$} (qAB)
      edge[bend left=10] node {$\tau$} (q123)
    (qAB)
      edge[swap, bend right=15] node {$\literal{a}$} (q123)
      edge[bend left=15] node {$\literal{b}$} (q123);
\end{tikzpicture}
```
Minimized version of @fig-bisim-sim-ts.
::::

:::

::: {#def-quotient-ts}
#### Quotient systems

Given an equivalence relation $\sim$ on states, and a transition system $\system=(\states,\actions,\step{})$,
each *equivalence class* for $p \in \states$ is defined $\eqclass{p}_{\sim} \defeq \set{p' \in \states \mid p \sim p'}$.

The *quotient system* is defined as $\quotient{\system}{\sim} \defeq (\quotient{\states}{\sim}, \actions, \step{}_{\sim})$, where $\quotient{\states}{\sim}$ is the set of equivalence classes $\set{ \eqclass{p}_{\sim} \mid p \in \states}$, and
$$P \step{\alpha}_\sim P' \text{ iff there are $p \in P$ and $p' \in P'$ such that $p \step{\alpha} p'$.}$$
:::

::: {#prp-bisim-minimization}
On the combined system of $\system$ and $\quotient{\system}{\beq{B}^{\system}}$, states and their derived class are bisimilar, $p \beq{B} \eqclass{p}_{\beq{B}^{\system}}$.
:::

The same reasoning does not apply to graph isomorphism:
In @exm-bisim-minimization, the terminal states might be graph-isomorphic, but merging them changes the number of states and thus prevents isomorphism between $\literal{T}$ and $\literal{T^m}$.

Together with the issue of congruence, we have now seen two reasons why graph isomorphism does not allow the kind of handling we hope for in behavioral equivalences.
Thus, the following will focus on equivalences of bisimilarity and below.
The next section will revisit a deeper, philosophical reason why bisimilarity is a reasonable limit of the properties one might care about in the comparison of processes.

## Modal Logics {#sec-hml}

Modal logics are logics in which one can formalize how facts in one possible world relate to other possible worlds.
In the computer science interpretation, the possible worlds are *program states*, and typical statements have the form:
“If $X$ happens during the execution, then $Y$ will happen in the next step.”

Each modal logic naturally characterizes a behavioral equivalence.
In this section, we show how such characterization works and argue that, for our purposes of comparative semantics, modal characterizations are a superb medium.
In the next chapter, the equivalence hierarchy will turn out to be a hierarchy of modal sublogics.

### Hennessy–Milner Logic to Express Observations

@hm1980hml introduce the modal logic that is now commonly called *Hennessy–Milner logic* (HML) as a “little language for talking about programs.”
The idea is that HML formulas express “experiments” or “tests” that an observer performs interacting with a program.

::: {#def-hml}
#### Hennessy–Milner logic

Formulas of *Hennessy–Milner logic* $\hml$ are given by the grammar:{{<isb datatype Hennessy_Milner_Logic hml_formula>}}
$$
\begin{array}{rcllr}
  φ & \grammardef &
    \hmlobs{α}φ & \quad\text{with } α ∈ \actions &
      \text{“observation”} \\
    & \grammaror & \hmland{i}{I}φ_i & \quad\text{with index set } I & \text{“conjunction”} \\
    & \grammaror & \hmlneg φ & & \text{“negation”} \\
\end{array}
$$
:::

We also write conjunctions as sets $\hmlands \set{φ_1, φ_2…}$.
The empty conjunction $\hmlands \varnothing$ is denoted by $\hmltrue$ and serves as the nil-element of HML syntax trees.
We also usually omit $\hmltrue$ when writing down formulas, e.g., shortening $\hmlobs{\literal a}\hmlobs{\literal b}\hmltrue$ to $\hmlobs{\literal a}\hmlobs{\literal b}$, which says that one may observe $\literal{a}$ and then $\literal{b}$.

We assume a form of associativity through the *convention that conjunctions are flat* in the sense that they do not immediately contain other conjunctions.
Thus, we consider $\hmlands \set{ \hmlobs{\literal a}, \hmlands \set{\hmlobs{\literal{b}}} }$ and $\hmlands \set{ \hmlobs{\literal a}, \hmlands \set{\hmlobs{\literal{b}}}, \hmltrue}$ just as different representatives of the flattened formula $\hmlands \set{\hmlobs{\literal a}, \hmlobs{\literal{b}}}$, stating that one may observe $\literal{a}$ *and* one may observe $\literal{b}$.

We do not restrict the size of index sets in conjunctions.
In particular, infinitary conjunctions are allowed, as we will discuss in @rem-image-finiteness.

The intuition behind HML is that it describes *what sequences of behavior* one may or may not *observe* of a system.
Observations $\hmlobs{α}…$ are used to build up possible action sequences;
conjunctions $\hmlands\set{…}$ capture branching points in decision trees;
and negations $\hmlneg …$ describe impossibilities.

::: {#def-hml-semantics}
#### HML semantics

Given a transition system $(\states,\actions,\step{})$, the semantics of HML $\semantics{\cdot} \colon \hml → \powerset{\states}$ is defined recursively by:{{<isb primrec Hennessy_Milner_Logic lts.satisfies>}}

$$
\begin{array}{rcl}
  \semantics{\hmlobs{α}φ} & ≔ & \set{p \mid \exists p' ∈ \semantics{φ} \ldotp p \step{α} p'}\\
  \semantics{\hmland{i}{I}φ_i} & ≔ & \bigcap_{i ∈ I} \semantics{φ_i}\\
  \semantics{\hmlneg φ} & ≔ & \states \setminus \semantics{φ}
\end{array}
$$
:::

::: {#exm-hml}
Let us consider some observations on the system of @exm-ts.

- $\semantics{\hmlobs{τ}\hmlobs{\literal a}} = \set{\literal P, \literal Q}$ as both, $\literal P$ and $\literal Q$, expose the trace $τ\literal{a}$,
- $\literal Q ∈ \semantics{\hmlobs{τ}\hmlands\set{\hmlobs{\literal a}, \hmlobs{\literal b}}}$, but $\literal P \notin \semantics{\hmlobs{τ}\hmlands\set{\hmlobs{\literal a}, \hmlobs{\literal b}}}$ as $\literal{Q}$ leaves the choice between $\literal{a}$ and $\literal{b}$ to the environment.
- $\literal P ∈ \semantics{\hmlobs{τ}\hmlneg\hmlobs{\literal a}}$, but $\literal Q \notin \semantics{\hmlobs{τ}\hmlneg\hmlobs{\literal a}}$ as $\literal{P}$ can internally decide against $\literal{a}$.
:::

### Characterizing Bisimilarity via HML

We can now add the middle layer of our overview graphic in @fig-equivalence-big-picture:
That two states are bisimilar precisely if they cannot be told apart using HML formulas.

::: {#def-distinctions}
#### Distinctions and equivalences

We say that formula $φ ∈ \hml$ *distinguishes* state $p$ *from* state $q$ if $p ∈ \semantics{φ}$ but $q \notin \semantics{φ}$.{{<isb abbreviation LTS_Semantics lts.distinguishes>}}

We say a sublogic $\observationsvar{} ⊆ \hml$ *preorders* state $p$ to $q$, $p \bpreordvar{\observationsvar{}} q$, if no $φ ∈ \observationsvar{}$ distinguishes $p$ from $q$.{{<isb definition LTS_Semantics lts.preordered>}}
If the preordering goes in both directions, we say that $p$ and $q$ are *equivalent* with respect to sublogic $\observationsvar{}$, written $p \beqvar{\observationsvar{}} q$.{{<isb definition LTS_Semantics lts.equivalent>}}
:::

By this account, $\hmlobs{τ}\hmlneg\hmlobs{\literal a}$ of @exm-hml distinguishes $\literal P$ from $\literal Q$.
On the other hand, $\hmlobs{τ}\hmlands\set{\hmlobs{\literal a}, \hmlobs{\literal b}}$ distinguishes $\literal Q$ from $\literal P$.
(The direction matters!)
For instance, the sublogic $\set{\hmlobs{τ}\hmlobs{\literal a}, \hmlobs{τ}\hmlobs{\literal b}}$ preorders $\literal P$ and $\literal Q$ in both directions; so the two states are equivalent with respect to this logic.

::: {#prp-hml-eq}
#### Transitivity for free

Consider an arbitrary HML sublogic $\observationsvar{} ⊆ \hml$.
Then, $\bpreordvar{\observationsvar{}}$ is a preorder, and $\beqvar{\observationsvar{}}$ an equivalence relation.{{<isb lemma LTS_Semantics lts.equivalent_equiv>}}
:::

::: {#lem-hml-eq-sim}
#### HML simulation

Hennessy–Milner logic equivalence $\beqvar{\hml}$ is a simulation relation.{{<isb lemma HML_Spectrum lts.hml_equiv_sim>}}
:::
::: proof
Assume it were not.
Then there would need to be $p \beqvar{\hml} q$ with step $p \step α p'$, and no $q'$ such that $q \step α q'$ and $p' \beqvar{\hml} q'$.
So there would need to be a distinguishing formula $φ_{q'}$ for each $q'$ that $q$ can reach by an $α$-step.
Consider the formula $φ_α ≔ \hmlobs{α}\hmland{q'}{\derivatives{q, α}} φ_{q'}$.
It must be true for $p$ and false for $q$, contradicting $p \beqvar{\hml} q$.
:::

::: {#lem-hml-eq-bisim-invariant}
#### Bisimulation invariance

If $p ∈ \semantics{φ}$ and $p \beq{B} q$ then $q ∈ \semantics{φ}$.{{<isb lemma HML_Spectrum lts.hml_bisim_invariant>}}
:::

::: proof
Induct over the structure of $φ$ with arbitrary $p$ and $q$.

- Case $p ∈ \semantics{\hmlobs{α}φ}$.
  Thus there is $p' ∈ \semantics{φ}$ with $p \step{α} p'$.
  Because $\beq{B}$ is a simulation according to @lem-bisim-bisim, this implies $q'$ with $p' \beq{B} q'$.
  The induction hypothesis makes $p' ∈ \semantics{φ}$ entail $q' ∈ \semantics{φ}$
  and thus $q ∈ \semantics{\hmlobs{α}φ}$.
- Case $p ∈ \semantics{\hmland{i}{I}φ_i}$.
  The induction hypothesis on the $φ_i$ directly leads to
  $q ∈ \semantics{\hmland{i}{I}φ_i}$.
- Case $p ∈ \semantics{\hmlneg φ}$.
  Symmetry of $\beq{B}$ according to @prp-sim-eq-rel, implies $q \beq{B} p$.
  By induction hypothesis, $q ∈ \semantics{φ}$ implies $p ∈ \semantics{φ}$.
  So, using contraposition, the case implies $q ∈ \semantics{\hmlneg φ}$.\qedhere
:::

Combining bisimulation invariance for one direction and that $\beq{\hml}$ is a symmetric simulation (@prp-hml-eq and @lem-hml-eq-sim) for the other, we obtain that $\hml$ precisely characterizes bisimilarity:

::: {#thm-hennessy-milner}
#### Hennessy–Milner theorem

Bisimilarity and HML equivalence coincide, that is, $p \beq{B} q$ precisely if $p \beq{\hml} q$.{{<isb theorem HML_Spectrum lts.Hennessy_Milner_theorem>}}
:::

::: {#rem-image-finiteness}
#### Infinitary conjunctions

In the standard presentation of the Hennessy–Milner theorem, image finiteness of the transition system is assumed.
This means that $\derivatives{p, α}$ is finite for every $p ∈ \states$ and $α \in \actions$.
The amount of outgoing transitions matters precisely in the construction of $φ_α$ in the proof of @lem-hml-eq-sim.
But as our definition of $\hml$ (@def-hml) allows infinite conjunctions $\hmland{i}{I} …$, we do not need an assumption here.
The implicit assumption is that the cardinality of index sets $I$ can match that of $\derivatives{p, α}$.
The original proof by @hm1980hml uses binary conjunction ($\varphi_1 \land \varphi_2$) and thus can only express finitary conjunctions.
:::

\bigskip

### The Perks of Modal Characterizations {#sec-perks-modal-characterizations}

There is merit in also characterizing other equivalences through sublogics $\observationsvar{} \subseteq \hml$.
Modal characterizations have four immediate big advantages:

Modal characterizations lead to *proper preorders and equivalences by design* due to @prp-hml-eq.
That is, if a behavioral preorder (or equivalence) is defined through modal logics, there is no need of proving transitivity and reflexivity (and symmetry).

Secondly, checking state equivalence for notions of $\hml$ sublogics *can soundly be reduced to checks on bisimulation-minimized systems* as the transformation does not affect the sets of observations for minimized states (by combining @thm-hennessy-milner and @prp-bisim-minimization).

Thirdly, modal characterizations can directly *unveil the hierarchy between preorders*, if defined cleverly, because of the following property.

::: {#prp-difference-contraposition}
If $\observationsvar{} \subseteq \observationsvar[\prime]{}$ then $p \bpreordvar{\observationsvar[\prime]{}} q$ implies $p \bpreordvar{\observationsvar{}} q$ for all $p,q$.{{<isb lemma LTS_Semantics lts_semantics.preorder_contraposition>}}
:::

Pay attention to the opposing directions of $\subseteq$ and implication here!

Fourthly, as a corollary of @prp-difference-contraposition, modal characterizations *ensure equivalences to be abstractions of bisimilarity*, which is a sensible base notion of equivalence.^[
  Among other things, bisimilarity checking has a better time complexity than other notions as will be discussed in @sec-equivalence-complexities.
]

In Chapter [-@sec-spectrum], we will discuss how the hierarchy of behavioral equivalences can be understood nicely and uniformly if viewed through the modal lens.

### Expressiveness and Distinctiveness

@prp-difference-contraposition actually is a weak version of another proposition about *distinctiveness* of logics.

::: {#def-leq-expressive}
#### Preorder of expressiveness
We say that an $\actions$-observation language $\observationsvar{}$ is *less or equal in expressiveness* to another $\observationsvar[\prime]{}$ iff, for any $\actions$-transition system, for each $φ ∈ \observationsvar{}$, there is $φ' ∈ \observationsvar[\prime]{}$ such that $\semantics{φ} = \semantics{φ'}$.
(The definition can also be read with regards to a fixed transition system $\system$.){{<isb definition LTS_Semantics lts_semantics.leq_expressive>}}
If the inclusion holds in both directions, $\observationsvar{}$ and $\observationsvar[\prime]{}$ are *equally expressive*.
:::

::: {#def-leq-distinctive}
#### Preorder of distinctiveness
We say that an $\actions$-observation language $\observationsvar{}$ is *less or equal in distinctiveness* to another $\observationsvar[\prime]{}$ iff, for any $\actions$-transition system and states $p$ and $q$, for each $φ ∈ \observationsvar{}$ that distinguishes $p$ from $q$, there is $φ' ∈ \observationsvar[\prime]{}$ that distinguishes $p$ from $q$.{{<isb definition LTS_Semantics lts_semantics.leq_distinctive>}}
If the inclusion holds in both directions, $\observationsvar{}$ and $\observationsvar[\prime]{}$ are *equally distinctive*.
:::

::: {#lem-subset-expressiveness-distinctiveness}

Subset relationship entails expressiveness, which entails distinctiveness.

- If $\observationsvar{} ⊆ \observationsvar[\prime]{}$, then $\observationsvar{}$ is less or equal in expressiveness to $\observationsvar[\prime]{}$.{{<isb lemma LTS_Semantics lts_semantics.subset_expressiveness>}}
- If $\observationsvar{}$ is less or equal in expressiveness to $\observationsvar[\prime]{}$, then $\observationsvar{}$ is less or equal in distinctiveness to $\observationsvar[\prime]{}$.{{<isb lemma LTS_Semantics lts_semantics.expressiveness_entails_distinctiveness>}}
:::

The other direction does not hold.
For instance, $\hml ⊈ \hml \setminus \set{\hmltrue}$, but they are equally expressive as $\hmlneg\hmlneg\hmltrue$ can cover for the removed element.
At the same time, $\set{\hmltrue}$ is more expressive than $\varnothing$, but equally distinctive.

The stronger version of @prp-difference-contraposition is thus:

::: {#prp-distinctiveness-contraposition}
If $\observationsvar{}$ is less or equal *in distinctiveness* to $\observationsvar[\prime]{}$ then $p \bpreordvar{\observationsvar[\prime]{}} q$ implies $p \bpreordvar{\observationsvar{}} q$ for all $p,q$.{{<isb lemma LTS_Semantics lts_semantics.preorder_expressiveness_contraposition>}}
:::

::: {#rem-flattened-conjunctions}
Through the lens of expressiveness, we can also justify why our convention to implicitly flatten conjunctions is sound:
As this does not change a conjunction's truth value, $\hml$ subsets with and without flattening-convention are equally expressive and thus distinctive.
:::

Often, an equivalence may be characterized by different sublogics.
In particular, one may find smaller characterizations as in the following example for bisimilarity, which will be relevant in the upcoming game characterizations.

::: {#def-game-formulas}
#### Bisimulation observations

Consider $\observations{\floor{B}} \subseteq \hml$ described by the following grammar:
$$
\begin{array}{rcll}
  φ^\mathrm{\floor{B}}
    & \grammardef & \hmlobs{α} \hmland{i}{I} φ^\mathrm{\floor{B}}_i \\
    & \grammaror  & \hmlneg φ^\mathrm{\floor{B}}
\end{array}
$$
:::

$\observations{\floor{B}}$ is a proper subset of $\hml$.
For instance, it lacks the observation $\hmlands\set{\hmlobs{\literal a}, \hmlobs{\literal b}}$.
Due to the subset relation, $\observations{\floor{B}}$ must be less or equal in expressiveness to $\hml$, but this inclusion too is strict as $\hmltrue$ cannot be covered for.
But both logics are equally distinctive!

::: {#lem-game-formula-hml}
$\observations{\floor{B}}$ and $\hml$ are equally distinctive.{{<isb theorem HML_Spectrum lts.hml_and_bisimulation_game_observations_equally_distinctive>}}
:::
::: proof

One direction is immediate from @lem-subset-expressiveness-distinctiveness as $\observations{\floor{B}} \subseteq \hml$.

For the other direction, we need to establish that, for each $φ ∈ \hml$ distinguishing some $p$ from some $q$, there is a $φ' ∈ \observations{\floor{B}}$ distinguishing $p$ from $q$.
We induct on the structure of $φ$ with arbitrary $p$ and $q$.

- Case $\hmlobs{α}φ$ distinguishes $p$ from $q$.
  Thus there is $p'$ such that $p \step{α} p'$ and that $φ$ distinguishes $p'$ from every $q' ∈ \derivatives{q, α}$.
  By induction hypothesis, there must be $φ'_{q'} ∈ \observations{\floor{B}}$ distinguishing $p'$ from $q'$ for each $q'$.
  Thus $\hmlobs{α}\hmland{q'}{\derivatives{q, α}} φ'_{q'} ∈ \observations{\floor{B}}$ distinguishes $p$ from $q$.
- Case $\hmland{i}{I}φ_i$ distinguishes $p$ from $q$.
  Therefore some $φ_i$ already distinguishes $p$ from $q$.
  By induction hypothesis, there must be $φ'_i ∈ \observations{\floor{B}}$ distinguishing $p$ from $q$.
- Case $\hmlneg φ$ distinguishes $p$ from $q$.
  Thus $φ$ distinguishes $q$ from $p$.
  By induction hypothesis, there is $φ' ∈ \observations{\floor{B}}$ distinguishing $q$ from $p$.
  Accordingly, $\hmlneg φ' ∈ \observations{\floor{B}}$ distinguishes $p$ from $q$.\qedhere
:::

The smaller bisimulation logic $\observations{\floor{B}}$ will turn out to be closely related to the game characterization of bisimilarity in @sec-bisim-game-hml.

## Games {#sec-games}

So far, we have only seen behavioral equivalences and modal formulas as mathematical objects and not cared about decision procedures.
This section introduces *game-theoretic characterizations* as a way of easily providing decision procedures for equivalences and logics alike.
Intuitively, the games can be understood as dialogs between a party that tries to defend a claim and a party that tries to attack it.

### Reachability Games

We use *Gale--Stewart-style reachability games* [in the tradition of @galeStewart1953infiniteGamesPerfectInformation] where the defender wins all infinite plays.

::: {#def-game}
#### Reachability game

A *reachability game* $\game = (G, G_\defender, \gamemoveblank)$ is played on a directed graph consisting of

- a set of *game positions* $G$, partitioned into
  - *defender positions* $G_\defender ⊆ G$
  - and *attacker positions* $G_\attacker ≔ G \setminus G_\defender$,
- and a set of *game moves* ${\gamemoveblank} ⊆ G × G$.{{<isb locale Equivalence_Games game>}}
:::

::: {#def-game-plays}
#### Plays and wins

We call the paths ${g_0}{g_1} … ∈ G^{\infty}$ with ${g_{i} \gamemoveblank g_{i+1}}$ *plays* of $\game$ from $g_0$,
where $G^{\infty}$ stands for finite and infinite words over $G$.
The defender *wins* infinite plays.
If a finite play $g_{0}\dots g_{n}\!\ngamemoveblank$ is stuck, the stuck player loses: The defender wins the play if $g_{n} ∈ G_\attacker$, and the attacker wins if $g_{n}∈ G_\defender$.
:::

Usually, games are nondeterministic, that is, players have choices how a play proceeds at their positions.
The player choices are formalized by *strategies*:

::: {#def-strategies}
#### Strategies and winning strategies

An *attacker strategy* is a (partial) function mapping play fragments ending at attacker positions to next positions to move to, $s_\attacker \colon G^*G_\attacker \to G$, where $g_\attacker \gamemoveblank s_\attacker(\rho g_\attacker)$ must hold for all $\rho g_\attacker$ where $s_\attacker$ is defined.

A play ${g_0}{g_1} … ∈ G^{\infty}$ is consistent with an attacker strategy $s_\attacker$ if, for all its prefixes $g_0 … g_i$ ending in $g_i \in G_\attacker$, $g_{i + 1} = s_\attacker(g_0 … g_i)$.

*Defender strategies* are defined analogously, $s_\defender \colon G^*G_\defender \to G$.

If $s$ ensures a player to win, $s$ is called a *winning strategy* for this player.
The player with a winning strategy from $g_{0}$ is said to *win* game $\game$ from $g_{0}$.

Usually, we will focus on positional strategies, that is, strategies that only depend on the most recent position, which we will type $s_\attacker \colon G_\attacker \to G$ (or $s_\defender \colon G_\defender \to G$, respectively).
:::

We call the positions where a player has a winning strategy their winning region.

::: {#def-winning-region}
#### Winning region

The set $\attackerwins ⊆ G$ of all positions $g$ where the attacker wins in $\game$ is called the *attacker winning region* of $\game$.
The defender winning region $\defenderwins$ is defined analogously.
:::

::: {#exm-formula-game}
#### A simple choice

Inspect the game in @fig-game-ex, where round nodes represent defender positions and rectangular ones attacker positions.
Its valid plays starting from $(\literal{1})$ are
$(\literal{1})$,
$(\literal{1})[\literal{2a}]$,
$(\literal{1})[\literal{2b}]$, and
$(\literal{1})[\literal{2a}](\literal{3})$.
The defender can win from $(\literal{1})$ with a strategy moving to $[\literal{2b}]$ where the attacker is stuck.
Moving to $[\literal{2a}]$ instead would get the defender stuck.
So, the defender winning region is $\defenderwins = \set{(\literal{1}),[\literal{2b}]}$ and the attacker wins $\attackerwins = \set{[\literal{2a}], (\literal{3})}$.
In @fig-game-ex, the winning regions are marked with blue for the defender and red for the attacker.

:::: {#fig-game-ex .column-margin}

::::::: {.content-visible when-profile="foc"}
```tikz
\begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=2cm,
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=1.5cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]
  \node[posStyle, defender, defWins] (p1){$(\literal{1})$};
  \node[posStyle, above right of=p1, attWins] (p2a){$[\literal{2a}]$};
  \node[posStyle, below right of=p1, defWins] (p2b){$[\literal{2b}]$};
  \node[posStyle, defender, right of=p2a, attWins] (p3){$(\literal{3})$};
  \path[>->]
    (p1)
      edge node {} (p2a)
      edge node {} (p2b)
    (p2a)
      edge node {} (p3);
\end{tikzpicture}
```
:::::::

::::::: {.content-visible unless-profile="foc"}
```tikz
\begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=2cm,
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=1.5cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]
  \node[posStyle, defender, defWins] (p1){$(\literal{1})$};
  \node[posStyle, below left of=p1, attWins] (p2a){$[\literal{2a}]$};
  \node[posStyle, below right of=p1, defWins] (p2b){$[\literal{2b}]$};
  \node[posStyle, defender, below of=p2a, attWins] (p3){$(\literal{3})$};
  \path[>->]
    (p1)
      edge node {} (p2a)
      edge node {} (p2b)
    (p2a)
      edge node {} (p3);
\end{tikzpicture}
```
:::::::

A simple game.
::::
:::

The games we consider are *positionally determined*.
This means, for each possible initial position, exactly one of the two players has a positional winning strategy $s$.

::: {#prp-determinacy}
#### Determinacy

Reachability games are positionally determined, that is,
for any game, each game position has exactly one winner:
$G = \attackerwins \cup \defenderwins$ and $\attackerwins \cap \defenderwins = \varnothing$,
and they can win using a positional strategy.^[
  This is just an instantiation of positional determinacy of parity games [@zielonka1998infiniteGameColoured].
  Parity games extend reachability games by number-coloring of positions.
  The defender only wins the infinite plays where the least color that appears infinitely often is even.
  Reachability games are the subclass of parity games only colored by 0.
]
:::

We care about reachability games because they are versatile in characterizing formal relations.
Everyday inductive (and coinductive) definitions can easily be encoded as games as in the following example.

::: {#exm-less-eq-game}
#### The $\leq$-Game

Consider the following recursive definition of a less-or-equal operator `≤` on natural numbers in some functional programming language.
(Consider `nat` to be defined as recursive data type `nat = 0 | Succ nat`.)

```haskell
    ( 0 ≤ m )     = True
(Succ n ≤ 0 )     = False
(Succ n ≤ Succ m) = (n ≤ m)
```

We can think of this recursion as a game where the attacker tries to prove that some natural number on the left is bigger than the right by always decrementing the left number and challenging the defender to do the same for the right stack too.
Whoever hits zero first, loses.

This means we distribute the roles such that the defender wins for output `True` and the attacker for output `False`.
The two base cases need to be dead ends for one of the players.

Formally, the game $\game_\literal{leq}$ consists of attacker positions $[n,m]$ and defender positions $(n,m)$ for all $n,m \in \nats$, connected by chains of moves:
$$
\begin{array}{rcl}
    [n + 1, m]
    & \gamemoveblank_\literal{leq}
    & (n, m)\\
    (n, m + 1)
    & \gamemoveblank_\literal{leq}
    & [n, m].
\end{array}
$$
An excerpt of the game graph below $[3,1]$ and $[1,2]$ is shown in @fig-leq-game.

::::{#fig-leq-game .column-margin}

::::::: {.content-visible when-profile="foc"}
```tikz
\begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=2cm, 
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=1.5cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]
  \node[posStyle, defender, attWins] (d10){$(1,0)$};
  \node[posStyle, attWins, left of=d10] (a20){$[2,0]$};
  \node[posStyle, defender, attWins, left of=a20] (d21){$(2,1)$};
  \node[posStyle, attWins, left of=d21] (a31){$[3,1]$};

  \node[posStyle, defWins, below of=d10] (a01){$[0,1]$};
  \node[posStyle, defender, defWins, left of=a01] (d02){$(0,2)$};
  \node[posStyle, defWins, left of=d02] (a12){$[1,2]$};

  \path[>->]
    (a31) edge node {} (d21)
    (d21) edge node {} (a20)
    (a20) edge node {} (d10)
    (a12) edge node {} (d02)
    (d02) edge node {} (a01);
\end{tikzpicture}
```
:::::::

::::::: {.content-visible unless-profile="foc"}
```tikz
\begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=2cm, 
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=1.5cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]
  \node[posStyle, defender, attWins] (d10){$(1,0)$};
  \node[posStyle, attWins, above of=d10] (a20){$[2,0]$};
  \node[posStyle, defender, attWins, above of=a20] (d21){$(2,1)$};
  \node[posStyle, attWins, above of=d21] (a31){$[3,1]$};

  \node[posStyle, defWins, right of=d10] (a01){$[0,1]$};
  \node[posStyle, defender, defWins, above of=a01] (d02){$(0,2)$};
  \node[posStyle, defWins, above of=d02] (a12){$[1,2]$};

  \path[>->]
    (a31) edge node {} (d21)
    (d21) edge node {} (a20)
    (a20) edge node {} (d10)
    (a12) edge node {} (d02)
    (d02) edge node {} (a01);
\end{tikzpicture}
```
:::::::

A part of $\game_{\literal{leq}}$.
::::

$\game_\literal{leq}$ now characterizes $\leq$ on $\nats$ in the sense that:
The defender wins $\game_\literal{leq}$ from $[n, m]$ precisely if $n \leq m$.
(Proof: Induct over $n$ with arbitrary $m$.)

The game is *boring* because the players do not ever have any choices.
They just count down their way through the natural numbers until they hit $[0, m - n]$ if $n \leq m$, or $(n - m - 1, 0)$ otherwise.

$\game_\literal{leq}$ is quite archetypical for the preorder and equivalence games that we use in the following pages.
But do not worry, the following games will demand the players to make choices.
:::

### The Semantic Game of HML {#sec-hml-semantic-game}

As first bigger example of how recursive definitions can be turned into games, let us quickly look at a standard way of characterizing the semantics of HML (@def-hml-semantics) through a game.
The defender wins precisely if the game starts from a state and formula such that the state satisfies the formula.

::: {#def-hml-game}
#### HML game

For a transition system $\system = (\states,\actions,\step{})$,
the *HML game* ${\game}_\hml^{\system} = (G_\hml,G_\defender,\gamemoveblank_\hml)$ is played on $G_\hml = \states × \hml$,
where the defender controls observations and negated conjunctions,
that is $(p, \hmlobs{α}φ) ∈ G_\defender$ and
$(p,\hmlneg\hmland{i}{I}φ_i) ∈ G_\defender$ (for all $φ,p,I$), and the attacker controls the rest.

- The defender can perform the moves:
  $$
  \begin{array}{rclr}
      (p, \hmlobs{α}φ)
      & \gamemoveblank_\hml
      & (p', φ)
      & \text{ if $p \step{α} p' \quad$ and} \\
      (p, \hmlneg{\hmland{i}{I}φ_i})
      & \gamemoveblank_\hml
      & (p, \hmlneg φ_i)
      & \text{ with $i ∈ I$;}
  \end{array}
  $$
- and the attacker can move:
  $$
  \begin{array}{rclr}
    (p, \hmlneg\hmlobs{α}φ)
      & \gamemoveblank_\hml
      & (p', \hmlneg φ)
      & \text{ if $p \step{α} p' \quad$ and} \\
    (p, \hmland{i}{I}φ_i)
      & \gamemoveblank_\hml
      & (p, φ_i)
      & \text{ with $i ∈ I \quad$ and} \\
    (p, \hmlneg\hmlneg φ)
      & \gamemoveblank_\hml
      & (p, φ).
      &
  \end{array}
  $$
:::

The intuition is that *disjunctive* constructs ($\hmlobs{\cdot}\cdots$, $\hmlneg \hmlands \cdots$) make it easier for a formula to be true and thus are controlled by the defender who may choose which of the ways to show truth is most convenient.
At *conjunctive* constructs ($\hmlneg\hmlobs{\cdot}\cdots$, $\hmlands \cdots$) the attacker chooses the option that is the easiest to disprove.
The most trivial case for the attacker to lose is $(p, \hmltrue)$.

::: {#exm-formula-game-cont}

The game of @exm-formula-game is exactly the HML game ${\game}_\hml^{\system_\literal{PQ}}$ for formula $\hmlobs{τ}\hmlneg\hmlobs{\literal a}\hmltrue$ and state $\literal P$ of @exm-hml with
$(\literal{1}) ≔ (\literal{P}, \hmlobs{τ}\hmlneg\hmlobs{\literal a}\hmltrue)$,
$[\literal{2a}] ≔ (\literal{p_a}, \hmlneg\hmlobs{\literal a}\hmltrue)$,
$[\literal{2b}] ≔ (\literal{p_b}, \hmlneg\hmlobs{\literal a}\hmltrue)$, and
$(\literal{3}) ≔ (\literal{p_1}, \hmlneg\hmltrue)$.

The defender winning region $\defenderwins = \set{(\literal{P}, \hmlobs{τ}\hmlneg\hmlobs{\literal a}\hmltrue), (\literal{p_b}, \hmlneg\hmlobs{\literal a}\hmltrue)}$ corresponds to the facts that $\literal{P} \in \semantics{\hmlobs{τ}\hmlneg\hmlobs{\literal a}\hmltrue}$ and $\literal{p_b} \in \semantics{\hmlneg\hmlobs{\literal a}\hmltrue}$.
:::

As the technicalities are tangential to this thesis, we state the characterization result without proof:^[
  A detailed presentation of a more general HML game, also extending to recursive HML, can be found in @woe2015caal2hml [Chapter 3].
]

::: {#lem-hml-semantic-game}
The defender wins ${\game}_\hml^{\system}$ from $(p, φ)$ precisely if $p ∈ \semantics{φ}$.
:::

### The Bisimulation Game

We now can add the bottom layer of @fig-equivalence-big-picture:
That bisimilarity can be characterized through a game, where the defender wins if the game starts on a pair of bisimilar states.
This approach has been popularized by @stirling1996modal.

::: {#def-bisim-game}
#### Bisimulation game

For a transition system $\system$, the *bisimulation game* $\gamebisim^{\system}$ is played on
attack positions $G_\attacker ≔ \states × \states$ and defense positions $G_\defender ≔ \actions × \states × \states$ with the following moves:{{<isb locale Equivalence_Games bisim_game>}}

- The attacker may *challenge simulation*
  $$[p, q] \quad \gamemoveblank_\notionname{B} \quad (α, p', q) \quad \text{if} \quad p \step{α} p',$$
- or the attacker may *swap sides*
  $$[p, q] \quad \gamemoveblank_\notionname{B} \quad [q, p], \vphantom{p'}$$
- and the defender *answers simulation challenges*
  $$(α, p', q) \quad \gamemoveblank_\notionname{B} \quad [p', q'] \quad \text{if} \quad q \step{α} q'.$$
:::

A schematic depiction of the game rules can be seen in @fig-game-scheme.
From dashed nodes, the game proceeds analogously to the initial attacker position.

::: {#fig-game-scheme fig-pos='tp'}

```tikz
\begin{tikzpicture}[>->,shorten <=1pt,shorten >=0.5pt,auto,node distance=2cm, rel/.style={dashed,font=\it},
  posStyle/.style={draw, inner sep=1ex,minimum size=1cm,minimum width=2cm,anchor=center,draw,black,fill=gray!5}]
    \node[posStyle, initial, initial text={}]
      (Att){$[p,q]$};
    \node[ellipse, draw, inner sep=1ex, minimum size=1cm,minimum width=2cm,fill=gray!5]
      (Def) [right = 1.5cm of Att] {$(\alpha, p', q)$};
    \node[posStyle, dashed]
      (AttContinue) [right = 1.5cm of Def] {$[p', q']$};
    \node[posStyle, dashed]
      (AttContinueSwap) [below = 1.2cm of AttContinue] {$[q, p]$};
    \path
      (Att)
        edge node {$p \step{\alpha} p'$} (Def)
        edge[bend right=10] node {} (AttContinueSwap)
      (Def)
        edge node {$q \step{\alpha} q'$} (AttContinue);
\end{tikzpicture}
```

Game scheme of the bisimulation game $\gamebisim$ (@def-bisim-game).
:::

::: {#exm-bisim-game}
Consider $\literal{p_{even}} \beq{B} \literal{p_{odd}}$ of @exm-graph-isomorphism.
The bisimulation game on this system is given by @fig-bisim-game-even-odd:

:::: {#fig-bisim-game-even-odd fig-pos="tp"}
  ```tikz
  \begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=3cm,
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=2.25cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]

    \node[posStyle, initial, initial text={}, defWins]
      (Att_EO){$[\literal{p_{even}}, \literal{p_{odd}}]$};
    \node[posStyle, defender, defWins]
      (Dfn_tOO) [below left of=Att_EO] {$(\tau, \literal{p_{odd}}, \literal{p_{odd}})$};
    \node[posStyle, defender, defWins]
      (Dfn_tEE) [below right of=Att_EO] {$(\tau, \literal{p_{even}}, \literal{p_{even}})$};
    \node[posStyle, defWins]
      (Att_OE) [below right of=Dfn_tOO] {$[\literal{p_{odd}}, \literal{p_{even}}]$};

    \path
      (Att_EO)
        edge[bend left = 10, pos=.3] node {swap} (Att_OE)
        edge[bend right = 10, swap] node {challenge} (Dfn_tOO)
      (Att_OE)
        edge[bend left = 10, pos=.3] node {swap} (Att_EO)
        edge[bend right = 10, swap] node {challenge} (Dfn_tEE)
      (Dfn_tOO)
        edge[bend right = 10, swap] node {answer\vphantom{lg}} (Att_OE)
      (Dfn_tEE)
        edge[bend right = 10, swap] node {answer\vphantom{lg}} (Att_EO)
    ;
  \end{tikzpicture}
  ```
  Bisimulation game under $\literal{p_{even}}, \literal{p_{odd}}$.
  Moves are annotated with the game rules from which they derive.
::::

Clearly, there is no way for the attacker to get the defender stuck.
Whatever strategy the attacker chooses, the game will go on forever, leading to a win for the defender.
That it is always safe for the defender to *answer* with moves to $[\literal{p_{even}}, \literal{p_{odd}}]$ and $[\literal{p_{odd}}, \literal{p_{even}}]$ corresponds to $\rel R ≔ \set{(\literal{p_{even}}, \literal{p_{odd}}), (\literal{p_{odd}}, \literal{p_{even}})}$ being a bisimulation.
:::

::: {#exm-bisim-sim-game}
#### A game of trolls

Let us recall @exm-bisim-sim of the “trolled philosophers,” where we determined $\literal{Q}$ and $\literal{T}$ to be non-bisimilar.
The bisimulation game graph for the system is depicted in @fig-bisim-sim-game, where we use the minimized version of $\literal{T}$ from @exm-bisim-minimization to fit the game graph onto the page.
(This means, technically, read $\literal{T}$ to denote $\literal{T^m}$.)

The attacker can win by moving $[\literal{Q}, \literal{T}]
\gamemoveblank_\notionname{B} [\literal{T}, \literal{Q}]
\gamemoveblank_\notionname{B} (\tau, \troll, \literal{Q})
\gamemoveblank_\notionname{B} [\troll, \literal{q_{ab}}]
\gamemoveblank_\notionname{B} [\literal{q_{ab}}, \troll]
\gamemoveblank_\notionname{B} (\literal{a}, \literal{q_1}, \troll)
\ngamemoveblank_\notionname{B}$.
Along this sequence of positions, the defender never has a choice and is stuck in the end.
The attacker exploits, that $\literal{T}$ can reach an early deadlock via $\literal{T} \step{\tau} \troll$.
:::

::: {#fig-bisim-sim-game fig-pos='tp' fig-env="figure*" .column-body-outset}
```tikz
%%| image-class: lightbox
\begin{adjustbox}{trim=1cm 0cm, max width=\linewidth, center}
  \begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=2cm,
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=2.25cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]

    \node[posStyle, initial, initial text={}, attWins]
      (Att_Q_Qp){$[\literal{Q}, \literal{T}]$};
    \node[posStyle, attWins]
      (Att_Qp_Q) [below = 2cm of Att_Q_Qp] {$[\literal{T}, \literal{Q}]$};
    \node[posStyle, defender, defWins]
      (Dfn_t_qab_Qp) [right = 1.5cm of Att_Q_Qp] {$(\tau, \literal{q_{ab}}, \literal{T})$};
    \node[posStyle, defWins]
      (Att_qab_tab) [below right = .15cm and 2cm of Dfn_t_qab_Qp] {$[\literal{q_{ab}}, \literal{t_{ab}}]$};
    \node[posStyle, defWins]
      (Att_tab_qab) [below = 1cm of Att_qab_tab] {$[\literal{t_{ab}}, \literal{q_{ab}}]$};
    \node[posStyle, attWins]
      (Att_qab_q3) [above right = .1cm and 1.5cm of Dfn_t_qab_Qp] {$[\literal{q_{ab}}, \troll]$};
    \node[posStyle, defender, attWins]
      (Dfn_a_q1_q3) [above right = .5cm and 2.5cm of Att_qab_q3] {$(\literal{a}, \literal{q_1}, \troll)$};
    \node[posStyle, defender, attWins]
      (Dfn_b_q2_q3) [below = .3cm of Dfn_a_q1_q3] {$(\literal{b}, \literal{q_2}, \troll)$};
    \node[posStyle, defender, defWins]
      (Dfn_t_qab_Q) [below = 1cm of Dfn_t_qab_Qp] {$(\tau, \literal{t_{ab}}, \literal{Q})$};
    \node[posStyle, defender, attWins]
      (Dfn_t_q3_Q) [below = 1cm of Dfn_t_qab_Q] {$(\tau, \troll, \literal{Q})$};
    \node[posStyle, attWins]
      (Att_q3_qab) [below right = .1cm and 1.5cm of Dfn_t_q3_Q] {$[\troll, \literal{q_{ab}}]$};
    \node[posStyle, defender, defWins]
      (Dfn_a_q1_tab) [below = .3cm of Dfn_b_q2_q3] {$(\literal{a}, \literal{q_1}, \literal{t_{ab}})$};
    \node[posStyle, defender, defWins]
      (Dfn_b_q2_tab) [below = .3cm of Dfn_a_q1_tab] {$(\literal{b}, \literal{q_2}, \literal{t_{ab}})$};
    \node[posStyle, defender, defWins]
      (Dfn_b_q3_qab) [below = .3cm of Dfn_b_q2_tab] {$(\literal{b}, \troll, \literal{q_{ab}})$};
    \node[posStyle, defender, defWins]
      (Dfn_a_q3_qab) [below = .3cm of Dfn_b_q3_qab] {$(\literal{a}, \troll, \literal{q_{ab}})$};
    \node[posStyle, defWins]
      (Att_q1_q3) [right = 1.8cm of Dfn_a_q1_tab] {$[\literal{q_1}, \troll]$};
    \node[posStyle, defWins]
      (Att_q2_q3) [right = 1.8cm of Dfn_b_q2_tab] {$[\literal{q_2}, \troll]$};
    \node[posStyle, defWins]
      (Att_q3_q2) [right = 1.8cm of Dfn_b_q3_qab] {$[\troll, \literal{q_2}]$};
    \node[posStyle, defWins]
      (Att_q3_q1) [right = 1.8cm of Dfn_a_q3_qab] {$[\troll, \literal{q_1}]$};


    \path
      (Att_Q_Qp)
        edge[bend left = 10] node {swap} (Att_Qp_Q)
        edge node {$\literal{Q} \step{\tau} \literal{q_{ab}}$} (Dfn_t_qab_Qp)
      ([xshift=-4mm] Att_qab_q3.south)
        edge[bend right = 35] node {} ([xshift=-4mm] Att_q3_qab.north)
      ([xshift=-2mm] Att_q3_qab.north)
        edge[bend left = 35] node[right] {swap} ([xshift=-2mm] Att_qab_q3.south)
      (Dfn_t_qab_Qp)
        edge node {$\literal{T} \step{\tau} \troll$} (Att_qab_q3)
        edge[swap] node {$\literal{T} \step{\tau} \literal{q_{ab}}$} (Att_qab_tab)
      (Att_qab_tab)
        edge[bend left = 10]  node {swap} (Att_tab_qab)
      (Att_tab_qab)
        edge[bend left = 10]  node {} (Att_qab_tab)
      (Att_Qp_Q)
        edge[bend left = 10] node {} (Att_Q_Qp)
        edge[swap] node {$\literal{T} \step{\tau} \literal{q_{ab}}$} (Dfn_t_qab_Q)
        edge[swap] node {$\literal{T} \step{\tau} \troll$} (Dfn_t_q3_Q)
      (Dfn_t_qab_Q)
        edge[swap] node {$\literal{Q} \step{\tau} \literal{q_{ab}}$} (Att_tab_qab)
      (Dfn_t_q3_Q)
        edge node[swap] {$\literal{Q} \step{\tau} \literal{q_{ab}}$} (Att_q3_qab)
      (Att_qab_q3)
        edge node {$\literal{q_{ab}} \step{\literal{a}} \literal{q_1}$} (Dfn_a_q1_q3)
        edge node {$\literal{q_{ab}} \step{\literal{b}} \literal{q_2}$} (Dfn_b_q2_q3)
      (Att_qab_tab)
        edge node[pos=.8] {$\literal{q_{ab}} \step{\literal{a}} \literal{q_1}$} (Dfn_a_q1_tab)
        edge node[swap, pos=.8] {$\literal{q_{ab}} \step{\literal{b}} \literal{q_2}$} (Dfn_b_q2_tab)
      (Att_tab_qab)
        edge node {$\literal{t_{ab}} \step{\literal{b}} \troll$} (Dfn_b_q3_qab)
        edge node[swap] {$\literal{t_{ab}} \step{\literal{a}} \troll$} (Dfn_a_q3_qab)
      (Dfn_a_q1_tab)
        edge node {$\literal{t_{ab}} \step{\literal{a}} \troll$} (Att_q1_q3)
      (Dfn_b_q2_tab)
        edge node {$\literal{t_{ab}} \step{\literal{b}} \troll$} (Att_q2_q3)
      (Dfn_b_q3_qab)
        edge node {$\literal{q_{ab}} \step{\literal{b}} \literal{q_2}$} (Att_q3_q2)
      (Dfn_a_q3_qab)
        edge node {$\literal{q_{ab}} \step{\literal{a}} \literal{q_1}$} (Att_q3_q1)
      ([yshift=.15cm]Att_q3_q1.east)
        edge[bend right = 30] node {} ([yshift=-.15cm]Att_q1_q3.east)
      (Att_q1_q3.east)
        edge[bend left = 35] node[right] {swap} (Att_q3_q1.east)
      ([yshift=.15cm]Att_q3_q2.east)
        edge[bend right = 30] node {} ([yshift=-.15cm]Att_q2_q3.east)
      (Att_q2_q3.east)
        edge[bend left = 35] node {} (Att_q3_q2.east)
    ;
  \end{tikzpicture}
\end{adjustbox}
```

Bisimulation game on non-bisimilar states $\literal{Q}$ and $\literal{T}$ of @exm-bisim-sim-game.
Moves are labeled by their justification.
Defender-won positions are tinted blue, attacker-won ones red.
:::

::: {#thm-bisim-game-characterization}
#### Stirling's game characterization

The defender wins the bisimulation game $\gamebisim^{\system}$ starting at attacker position $[p, q]$ precisely if $p \beq{B} q$.{{<isb theorem Equivalence_Games bisim_game.bisim_game_characterization>}}
:::
::: proof
Sketch for both directions:

- If $\rel R$ is a symmetric simulation with $(p_0,q_0) ∈ \rel R$,
  then the following positional defender strategy is winning from $[p_0, q_0]$:{{<isb lemma Equivalence_Games bisim_game.bisim_implies_defender_winning_strategy>}}
  $$s((α, p', q)) ≔ [p', \operatorname{choose} q'\ldotp (p', q') ∈ \rel R \land q \step{α} q'].$$
- If there is a positional defender strategy $s$ winning from $[p_0, q_0]$,
  then the following relation $\rel{R}_s$ with $(p_0,q_0) ∈ \rel{R}_s$ is a symmetric simulation:{{<isb lemma Equivalence_Games bisim_game.defender_winning_strategy_implies_bisim>}}
  $$\rel{R}_s ≔ \set{(p,q) \mid \text{there is a play $(p_0, q_0),\dots,(p,q)$ following strategy $s$}}.\qedhere$$
:::

::: {#rem-computer-game}
#### Playing equivalence games

One of the big advantages of game characterizations is that they provide a way to discuss equivalence and inequivalence interactively among humans.
An example of such a situation can be seen in @fig-defense-game.

:::: {#fig-defense-game .column-margin}

{{< pic "img/defense-game.jpg" >}}

The author, playing the bisimulation game on @exm-ts during his PhD defense.
The attacker (red puppet) was controlled by van Glabbeek and beat the defender (blue puppet), briefly confusing Groote as to whether this meant that the PhD defense has already failed at this point.
Luckily, it was not.
{{< photo_credits "Hanna Wesner" >}}
::::

If you want to try it at home, there also are several computer game implementations of bisimulation games.

:::: {#fig-peacock-game .column-margin}

{{< pic "img/peacock-bisim-video-game.png" >}}

Screenshot of [Peacock's bisimulation computer game](https://games.equiv.io/play/rvg-game).
(In the computer game, the colors are coded inversely to our presentation.
The  blue character represents the attacker-controlled state.)
::::

For instance, @peacock2020videoGameEquivalences implements a game about simulation and bisimulation as well as several weaker notions.
The human plays the attacker trying to point out the inequivalence of systems according to the rules of @def-bisim-game.
@fig-peacock-game shows a screenshot of said game.
It can be played on <https://games.equiv.io/play/rvg-game/>.
:::

::: {#rem-leq-bisim-game}
#### Number comparison as simulation game

If one plays the bisimulation game of @def-bisim-game without the swapping moves, it will characterize the simulation preorder.

Consider the family of processes $\literal{N}_n$ with $n \in \nats$.
Define $\literal{N}_0 ≔ \ccsnull$ and $\literal{N}_{n + 1} ≔ \ccsprefix{\literal{one}} \literal{N}_n$.
Then, the simulation game played from $[\literal{N}_{n}, \literal{N}_{m}]$ is isomorphic to the $\leq$-game $\game_{\literal{leq}}$ from @exm-less-eq-game.
Therefore, the defender wins $[\literal{N}_{n}, \literal{N}_{m}]$ in the simulation game precisely if they win $[n, m]$ in the $\leq$-game.
We can compare numbers $n \leq m$ by comparing programs $\literal{N}_{n} \bpreord{S} \literal{N}_{m}$!

In this sense, comparisons of programs and of numbers are … comparable.
:::

\bigskip

### Deciding Reachability Games {#sec-deciding-reachability-games}

All we need to turn a game characterization into a decision procedure is a way to decide which player wins a position.
With this, ${\game}_\hml$ of @def-hml-game entails a model checking procedure for HML and ${\game}_{\notionname{B}}$ a bisimulation checking algorithm on finite-state systems.

@algo-deciding-games describes how to compute who wins a finite reachability game for each position in time linear to the size of the game graph $\bigo{\relsize{\gamemoveblank}}$.

::: {#algo-deciding-games algo-pos="t"}

$$
\begin{array}{rl}
  {\scriptstyle  1} & \kw{def} \variable{compute\_winning\_region}(\game=(G,G_\defender,\gamemoveblank)) \colon \\
  {\scriptstyle  2} & \quad \variable{defender\_options} ≔
    [g \mapsto n \mid g \in G_\defender \land n = \relsize{\set{g' \mid g \gamemoveblank g'}}] \\
  {\scriptstyle  3} & \quad \variable{attacker\_win} ≔ \varnothing \\
  {\scriptstyle  4} & \quad \variable{todo} ≔ \set{g\in G_\defender \mid \variable{defender\_options}[g]=0} \\
  {\scriptstyle  5} & \quad \kw{while} \variable{todo} \neq \varnothing \colon \\
  {\scriptstyle  6} & \quad \quad \variable{g} ≔ \kw{some} \variable{todo} \\
  {\scriptstyle  7} & \quad \quad \variable{todo} ≔ \variable{todo} \setminus \set{\variable{g}} \\
  {\scriptstyle  8} & \quad \quad \kw{if} \variable{g} \notin \variable{attacker\_win} \colon \\
  % note: the if should not be necessary for sets.
  {\scriptstyle  9} & \quad \quad \quad \variable{attacker\_win} ≔ \variable{attacker\_win} \cup \set{\variable{g}} \\
  {\scriptstyle 10} & \quad \quad \quad \kw{for} \variable{g_{p}} \in (\cdot \gamemoveblank \variable{g}) \colon \\
  {\scriptstyle 11} & \quad \quad \quad \quad \kw{if} \variable{g_{p}} \in G_\attacker \colon \\
  {\scriptstyle 12} & \quad \quad \quad \quad \quad \variable{todo} ≔ \variable{todo} \cup \set{\variable{g_{p}}} \\
  {\scriptstyle 13} & \quad \quad \quad \quad \kw{else} \colon \\
  {\scriptstyle 14} & \quad \quad \quad \quad \quad \variable{defender\_options}[\variable{g_{p}}]≔\variable{defender\_options}[\variable{g_{p}}]-1 \\
  {\scriptstyle 15} & \quad \quad \quad \quad \quad \kw{if} \variable{defender\_options}[\variable{g_{p}}]=0 \colon \\
  {\scriptstyle 16} & \quad \quad \quad \quad \quad \quad \variable{todo} ≔ \variable{todo} \cup \set{\variable{g_{p}}} \\
  {\scriptstyle 17} & \quad \attackerwins ≔ \variable{attacker\_win} \\
  {\scriptstyle 18} & \quad \kw{return} \attackerwins
\end{array}
$$

Deciding the attacker winning region $\attackerwins$ of a reachability game $\game$ in linear time of $\relsize{\gamemoveblank}$ and linear space of $\relsize{G}$.
:::

Intuitively, $\variable{compute\_winning\_region}$ first assumes that the defender were to win everywhere and that each outgoing move of every position might be a winning option for the defender.
Over time, every position that is determined to be lost by the defender is added to a $\variable{todo}$ list.^[
  Variants of this algorithm and explanation have also been used in @bisping2018coupledsim and @bjn2022decidingAllBehavioralEqs.
]

At first, the defender loses immediately exactly at the defender's dead ends.
Each defender-lost position is added to the $\variable{attacker\_win}$ set.
To trigger the recursion, each predecessor is noted as defender-lost, if it is controlled by the attacker, or the amount of outgoing defender options is decremented if the predecessor is defender-controlled.
If the count of a predecessor position hits 0, the defender also loses from there.

Once we run out of $\variable{todo}$ positions, we know that the attacker has winning strategies exactly for each position we have visited.

The following @tbl-game-example-execution lists how @algo-deciding-games computes the winning region $\attackerwins = \set{[\literal{2a}], (\literal{3})}$ of the simple choice game of @exm-formula-game.


```{=latex}
% fix to make the table float in spite of Pandoc's hardcoded longtable usage...
% push to next page to fix the problem of longtable breaking pages with other floats -_-
%\afterpage{\clearpage
%\begin{table}%[b!]
```

| $\variable{g}$ | $\variable{defender\_options}$ | $\variable{todo}$ |
|------|---------------|------|
|   -    |  $(\literal{1}) \mapsto 2$, $(\literal{3}) \mapsto 0$ | $(\literal{3})$  |
| $(\literal{3})$ | $(\literal{1}) \mapsto 2$, $(\literal{3}) \mapsto 0$ | $[\literal{2a}]$  |
| $[\literal{2a}]$ | $(\literal{1}) \mapsto 1$, $(\literal{3}) \mapsto 0$ | $\varnothing$ |

: Solving the game of @exm-formula-game. {#tbl-game-example-execution}

``` {=latex}
%\end{table}
%}
```

\noindent
As this game corresponds to the HML game by @exm-formula-game-cont, the computation that the defender wins $(\literal{1})$ checks that $\hmlobs{τ}\hmlneg\hmlobs{\literal a}\hmltrue$ is true for state $\literal P$ of @exm-hml.

The inner loop of @algo-deciding-games clearly can run at most $\relsize{\gamemoveblank}$-many times.
Using sufficiently clever data structures, the algorithm hence shows:

::: {#prp-reachability-game-complexity}
Given a finite reachability game $\game=(G,G_\defender,\gamemoveblank)$,
the attacker's winning region $\attackerwins^\game$ (and $\defenderwins^\game$ as well) can be computed in $\bigo{\relsize{\gamemoveblank}}$ time and $\bigo{\relsize{G}}$ space.
:::

Everything we can characterize as a reachability game, can thus be easily decided.

So, by now we know a world where equivalences are nice to characterize, *modal logics*, and a world where they are nice to compute: *games*.
Obviously, there must be a link!
Making this link explicit yields the *core proof approach* for the rest of this thesis.

### How Bisimulation Game and HML Are Connected {#sec-bisim-game-hml}

Bisimulation game and Hennessy–Milner logic connect in a beautiful way.
This connection usually receives less attention than Hennessy–Milner theorem and Stirling's characterization.
But it is the key insight for the main results of later chapters.

Let us briefly imagine a world without a dedicated bisimulation game.
The Hennessy–Milner theorem implies that we could directly use the HML game of @def-hml-game to describe bisimilarity:

::: {#def-naive-bisim-game}
#### Naive bisimulation game

We extend the HML game of @def-hml-game by the following prefix:

1. To challenge $[p,q]$, the attacker picks a formula $φ ∈ \hml$ (claiming that $φ$ distinguishes the states) and yields to the defender $(φ, p, q)$.
2. The defender decides where to start the HML game:
    1. Either at $(p, \hmlneg φ)$ (claiming $φ$ to be non-distinguishing because it is untrue for $p$)
    2. or at $(q, φ)$ (claiming $φ$ to be non-distinguishing because it is true for $q$).
3. After that, the turns proceed as prescribed by @def-hml-game.

:::

This naive game, too, has the property that the defender wins from $[p,q]$ iff $p \beq{B} q$.
The downside of the game is that the attacker has infinitely many options $φ ∈ \hml$ to pick from!

The proper bisimulation game of @def-bisim-game, on the other hand, is *finite for finite transition systems*.
Therefore, it induces decision procedures by the reasoning of @sec-deciding-reachability-games.

We will now argue that the *bisimulation game actually is a variant of the naive game*, where (1) the attacker names their formula *gradually*, and (2) the formulas stem from $\observations{\floor{B}} \subseteq \hml$ of @def-game-formulas.
To this end, we are going to show that attacker's winning strategies imply distinguishing formulas, and that a distinguishing formula from $\observations{\floor{B}}$ certifies the existence of winning attacker strategies.

::: {#exm-bisim-sim-game-formulas}
#### Formulating attacks

Let us illustrate how to derive distinguishing formulas using the game of @exm-bisim-sim-game.

Recall that the attacker wins by moving $[\literal{Q}, \literal{T}]
\gamemoveblank_\notionname{B} [\literal{T}, \literal{Q}]
\gamemoveblank_\notionname{B} (\tau, \troll, \literal{Q})
\gamemoveblank_\notionname{B} [\troll, \literal{q_{ab}}]
\gamemoveblank_\notionname{B} [\literal{q_{ab}}, \troll]
\gamemoveblank_\notionname{B} (\literal{a}, \literal{q_1}, \troll)
\ngamemoveblank_\notionname{B}$.
In @fig-bisim-sim-game-formulas, we label the game nodes with the (sub-)formulas this strategy corresponds to.
The cloud indicates where we omit some region where the defender wins.
Swap moves become negations, and simulation moves become observations with a conjunction of formulas for each defender option.
This attacker strategy can thus be expressed by $\hmlneg\hmlobs{\tau}\hmlands\set{\hmlneg\hmlobs{\literal{a}}\hmltrue} \in \observations{\floor{B}}$.
We will call such formulas “strategy formulas.”
:::

::: {#fig-bisim-sim-game-formulas fig-pos='t' fig-env="figure*"}
```tikz
%%| image-class: lightbox
\begin{adjustbox}{max width=\textwidth, center}
  \begin{tikzpicture}[>->, shorten <=1pt, shorten >=0.5pt, auto, node distance=2cm,
    posStyle/.style={draw, inner sep=1ex, minimum size=1cm, minimum width=2.25cm, anchor=center, draw, black, fill=gray!5},
    defender/.style={ellipse, inner sep=0ex},
    defWins/.style={fill=blue!5},
    attWins/.style={fill=red!5}]

    \node[posStyle, initial, initial text={}, attWins, label={100:$\textcolor{red}{\hmlneg\hmlobs{\tau}\hmlands\set{\hmlneg\hmlobs{\literal{a}}\hmltrue}}$}]
      (Att_Q_Qp){$[\literal{Q}, \literal{T}]$};
    \node[posStyle, attWins, label={100:$\textcolor{red}{\hmlobs{\tau}\hmlands\set{\hmlneg\hmlobs{\literal{a}}\hmltrue}}$}]
      (Att_Qp_Q) [below = 2cm of Att_Q_Qp] {$[\literal{T}, \literal{Q}]$};
    \node[posStyle, defender, defWins]
      (Dfn_t_qab_Qp) [right = 1.5cm of Att_Q_Qp] {$(\tau, \literal{q_{ab}}, \literal{T})$};
    \node[dotted, cloud, cloud puffs=9,cloud puff arc=105, aspect=2, defWins, inner sep=.01cm, align=center]
      (Att_qab_qab) [below right = .1cm and 1.5cm of Dfn_t_qab_Qp] {defender\\ wins};
    \node[posStyle, attWins, label={100:$\textcolor{red}{\hmlobs{\literal{a}}\hmltrue}$}]
      (Att_qab_q3) [above right = .1cm and 1.5cm of Dfn_t_qab_Qp] {$[\literal{q_{ab}}, \troll]$};
    \node[posStyle, attWins, defender, above right = .1cm and 1.5cm of Att_qab_q3]
      (Dfn_a_q1_q3) {$(\literal{a}, \literal{q_1}, \troll)$};
    \node[posStyle,  attWins, defender]
      (Dfn_b_q2_q3) [below right = .1cm and 1.5cm of Att_qab_q3] {$(\literal{b}, \literal{q_2}, \troll)$};
    \node[posStyle, defender, defWins]
      (Dfn_t_qab_Q) [below = 1cm of Dfn_t_qab_Qp] {$(\tau, \literal{t_{ab}}, \literal{Q})$};
    \node[posStyle, attWins, defender]
      (Dfn_t_q3_Q) [below = 1cm of Dfn_t_qab_Q] {$(\tau, \troll, \literal{Q})$};
    \node[posStyle, attWins, label={100:$\textcolor{red}{\hmlneg\hmlobs{\literal{a}}\hmltrue}$}]
      (Att_q3_qab) [below = 1cm of Att_qab_qab] {$[\troll, \literal{q_{ab}}]$};

    \path
      (Att_Q_Qp)
        edge[bend left = 10] node {} (Att_Qp_Q)
        edge node {} (Dfn_t_qab_Qp)
      (Att_qab_q3)
        edge[bend left = 65] node {} (Att_q3_qab)
      (Att_q3_qab)
        edge[bend right = 60] node {} (Att_qab_q3)
      (Dfn_t_qab_Qp)
        edge node {} (Att_qab_q3)
        edge node {} (Att_qab_qab)
      (Att_Qp_Q)
        edge[bend left = 10] node {} (Att_Q_Qp)
        edge node {} (Dfn_t_qab_Q)
        edge node {} (Dfn_t_q3_Q)
      (Dfn_t_qab_Q)
        edge node {} (Att_qab_qab)
      (Dfn_t_q3_Q)
        edge node {} (Att_q3_qab)
      (Att_qab_q3)
        edge node {} (Dfn_a_q1_q3)
        edge node {} (Dfn_b_q2_q3)
    ;
  \end{tikzpicture}
\end{adjustbox}
```

The bisimulation game of @exm-bisim-sim-game-formulas with attacker formulas.
:::

\noindent
More generally, the following lemmas explain the construction of distinguishing formulas from attacker strategies, and back.
They are a blueprint of game characterization proofs throughout the thesis.

We refer to the property that attacker wins in a game represent distinguishing formulas as “distinction soundness” of a game.

::: {#lem-attacks-imply-formulas}
#### Distinction soundness

Let function $s$ be a positional winning strategy for the attacker on $\gamebisim$ from $[p,q]$.
Construct formulas recursively from game positions, ${φ}_{s}(g)$, as follows:
$$
φ_{s}([p,q]) ≔ \begin{cases}
  \hmlneg φ_{s}([q,p])  & \text{if } s([p,q]) = [q,p] \\
  \hmlobs{\alpha} \hmlands \set{ φ_{s}([p',q']) \mid q \step{\alpha} q' } & \text{if } s([p,q]) = (\alpha,p',q)
\end{cases}
$$
Then $φ_{s}$ is defined for $[p,q]$ and distinguishes $p$ from $q$.
Also, $φ_{s}([p,q]) ∈ \observations{\floor{B}}$.
:::
::: proof
1. The recursive construction works to define $φ_{s}([p,q])$ as $s$ must induce a well-founded order on game positions^[
    An order on a set $A$ is well-founded iff each nonempty subset $A' \subseteq A$ has a minimal element $\min A'$.
    In the game, the minima correspond to the defender dead ends the attacker is navigating towards.
  ] in order for the attacker to win, and as the recursive invocations remain in the attacker winning strategy.
2. The distinction can be derived by induction on the construction of $φ_{s}([p,q])$:
  Assume for $p',q'$ appearing in recursive invocations of the definition of $φ_{s}$ that $φ_{s}([p', q'])$ distinguishes them and that $φ_{s}([p', q']) ∈ \observations{\floor{B}}$.
  We have to show that the constructions in $φ_{s}$ still fulfill this property:
  
   - As $φ_{s}([p',q'])$ distinguishes $p'$ from $q'$, its negation $\hmlneg φ_{s}([p',q'])$ must distinguish $q'$ from $p'$ by the HML semantics.
     Moreover, the grammar of  @def-hml-game is closed under negation.
   - For $\hmlobs{\alpha} \hmlands \set{ φ_{s}([p',q']) \mid q \step{\alpha} q' }$ to distinguish $p$ from $q$,
     there must be $p \step{\alpha} p^* \in \semantics{\hmlands \set{ φ_{s}([p',q']) \mid q \step{\alpha} q' }}$, and for all $q^*$ with $q \step{\alpha} q^*$ it must be that $q^* \notin \semantics{\hmlands \set{ φ_{s}([p',q']) \mid q \step{\alpha} q' }}$.
     We choose $p^* = p'$, because,
     as $s$ is an attacker winning strategy, $s([p, q]) = (\alpha, p', q)$ is a valid move with $p \step{\alpha} p'$.
     Also, all $q'$ the defender may select in answers remain in the winning domain of the attacker, and we may use the induction hypothesis that $q' \notin \semantics{φ_{s}([p',q'])}$.
    Therefore, for each $q^*$ there is a false conjunct with $q' = q^*$ in $\hmlands \set{ φ_{s}([p',q']) \mid q \step{\alpha} q' }$ that proves $q^* \notin \semantics{\hmlands \set{ φ_{s}([p',q']) \mid q \step{\alpha} q' }}$. \qedhere
:::

We say that a game moreover is distinction-complete if distinguishing formulas of a sublogic can be mirrored by attacker strategies.

::: {#lem-formulas-imply-attack}
#### Distinction completeness

If $φ ∈ \observations{\floor{B}}$ distinguishes $p$ from $q$, then the attacker wins from $[p,q]$.
:::
::: proof

By induction on the derivation of $φ ∈ \observations{\floor{B}}$ according to the definition from @def-game-formulas with arbitrary $p$ and $q$.

- Case $φ = \hmlobs{α} \hmland{i}{I} φ_i$.
  As $φ$ distinguishes $p$ from $q$, there must be a $p'$ such that $p \step{α} p'$ and that $\hmland{i}{I} φ_i$ distinguishes $p'$ from every $q' ∈ \derivatives{q, α}$.
  That is, for each $q' ∈ \derivatives{q, α}$, at least one $φ_i \in \observations{\floor{B}}$ must be false.
  By induction hypothesis, the attacker thus wins each $[p',q']$.
  As these attacker positions encompass all successors of $(α, p', q)$, the attacker also wins this defender position and can win from $[p,q]$ by moving there with a simulation challenge.
- Case $φ = \hmlneg φ'$.
  As $φ$ distinguishes $p$ from $q$, $φ'$ distinguishes $q$ from $p$.
  By induction hypothesis, the attacker wins $[q, p]$.
  So they can also win $[p, q]$ by performing a swap.\qedhere
:::

@lem-attacks-imply-formulas and @lem-formulas-imply-attack, together with the fact that $\observations{\floor{B}}$ and $\hml$ are equally distinctive (@lem-game-formula-hml), yield:

::: {#thm-game-formulas}
The attacker wins $\gamebisim$ from $[p,q]$ precisely if there is a formula $φ ∈ \hml$ distinguishing $p$ from $q$.
:::

With @thm-game-formulas, we have added the last arrow on the right side of @fig-equivalence-big-picture.

Of course, @thm-game-formulas could also be arrived at by gluing together the Hennessy–Milner theorem on bisimulation (@thm-hennessy-milner) and Stirling's bisimulation game characterization (@thm-bisim-game-characterization), modulo the determinacy of games.
But @thm-game-formulas transports the following deeper insight:

The bisimulation game actually is a *game of an attacker assembling a distinguishing formula* from $\observations{\floor{B}}$.
The game rules for attacker moves follow the grammar of $\observations{\floor{B}}$.
But parts of the HML semantics are baked into the game:
Intuitively, the attacker must propose formulas that are true-by-construction for the left-hand state.
To disprove the distinction, the defender may point out how the formula is also satisfied by the right-hand state.
Negation turns the tables.

The rest of this thesis is about leveraging this intuition to address every behavioral equivalence.
We will meet @thm-game-formulas again three times---each time in a more abstract form.^[
  And for the most abstract incarnation, there will even be an Isabelle/HOL formalization in @sec-isabelle-formalization.
]

## Discussion {#sec-preliminaries-discussion}

This chapter has taken a tour of characterizations for standard notions of behavioral preorder and equivalence on transition systems such as trace equivalence and bisimilarity.
The aim of this has been to prepare a generic framework to characterize and decide behavioral equivalences.
So far, we have only instantiated the framework for bisimilarity, but the rest will follow.

{{< paragraph_heading "Perspicuous algorithmics." >}}
In constructing the relationships of @fig-equivalence-big-picture for bisimilarity, we have collected the theoretical ingredients for a *certifying algorithm* to check bisimilarity of states.

::: {#fig-game-algo-overview fig-pos='t' fig-env="figure*"}
```tikz

%\begin{adjustbox}{max width=\textwidth, center}
  \begin{tikzpicture}[auto,node distance=2.7cm,
    algstep/.style={minimum width=2.5cm, minimum height=1.2cm, draw=gray, rectangle,align=center,rounded corners}]
    \node[algstep] (TS) {$p$ and $q$ in\\ system $\system$};
    \node[algstep, below of=TS, node distance=7.8cm] (BisimGame) {Bisimulation \\ game ${{\game}^{\system}_{\notionname{B}}}$};
    \node[algstep, right of=BisimGame, node distance=5cm] (WinningRegion) {Winning regions\\$\attackerwins^{{\game}^{\system}_{\notionname{B}}}$ and $\defenderwins^{{\game}^{\system}_{\notionname{B}}}$};
    \node[draw, diamond, above of=WinningRegion, node distance=2cm, minimum width=.8cm, minimum height=.8cm] (Decision) {};
    \node[algstep, above left of=Decision] (Relation) {Bisimulation \\ relation $\rel{R}_s$};
    \node[algstep, above right of=Decision] (Formula) {Distinguishing \\ formula $\varphi_s$};
    \node[algstep, above of=WinningRegion, node distance=7.8cm] (Output) {Yes / No};
    \node[above of=Relation, node distance=2.5cm] (Yes) {Certifiably yes $✔$};
    \node[above of=Formula, node distance=2.5cm] (No) {$✗$ Certifiably no};
    \path
      (TS) edge[->, swap] node {Def.~\ref{def-bisim-game}} (BisimGame)
      (TS) edge[->, dashed] node {Bisimilar?} (Output)
      (BisimGame) edge[->] node {Alg.~\ref{algo-deciding-games}} (WinningRegion)
      (WinningRegion) edge[->, swap] node {$[p,q] \in \defenderwins^{{\game}^{\system}_{\notionname{B}}}$} (Decision)
      (Decision) edge[->] node {Yes: Thm.~\ref{thm-bisim-game-characterization}\vphantom{p}} (Relation)
      (Decision) edge[->, swap] node {No: Lem.~\ref{lem-attacks-imply-formulas}\vphantom{p}} (Formula)
      (Relation) edge[->] node[align=right] {Check relation \\ fulfills bisimulation \\ Def.~\ref{def-bisimilarity}\vphantom{p}} (Yes)
      (Formula) edge[->, swap] node[align=left] {Check distinction \\ using HML game \\ Def~\ref{def-hml-game} + Alg.~\ref{algo-deciding-games}\vphantom{p}} (No);
    \draw
      (Output.south) |- (Yes.east)
      (Output.south) |- (No.west);
  \end{tikzpicture}
%\end{adjustbox}
```

Checking bisimilarity and providing certificates.
:::

@fig-game-algo-overview describes how to not only answer the question whether two states $p$ and $q$ are bisimilar, but how to also either provide a bisimulation relation or a distinguishing formula for the two as certificates for the answer.
(The arrows stand for computations, the boxes for data.)

In this view, the game of possible distinctions and their preventability between attacker and defender serves as the “ground truth” about the bisimilarity of two states.
Bisimulation relations and modal formulas only appear as certificates of defender and attacker strategies, mediating between game and transition system.
The Hennessy--Milner theorem emerges on this level as a *shadow of the determinacy* of the bisimulation game (@idea-games).
This whole framework draws heavily from @stirling1996modal.
The following chapters will reveal how the game framework generalizes to check multiple equivalences.

{{< paragraph_heading "Alternatives." >}}
There are alternative frameworks for deciding behavioral equivalences that this thesis will not be using:

- **Fixed-point iteration.**
  Simulation-like behavioral equivalences and preorders can be expressed as greatest fixed points of monotonic functions [@ails2007reactiveSystems § 4.3].
  Fixed-point iteration computes such relations on finite-state transition systems by initially assuming that all states are related and iteratively removing pairs that locally violate the (bi-)simulation condition.
  This process continues until no such pairs remain.
  In effect, a chain reaction happens analogous to the one that @algo-deciding-games performs on the bisimulation game.
  Compared to the game approach, fixed-point iteration usually is slower as it lacks knowledge about logical connections between pairs in the candidate relation.
- **Partition refinement.**
  The fastest algorithms for bisimilarity on transition systems use partition refinement [@paigetarjan1987partitionrefinement].
  Partitions represent equivalence relations as colorings on graphs, which is linear in the state space $\relsize{\states}$ (opposed to quadratic combinations for pairs in relations for fixed points and attacker positions for games).
  Intuitively, parts of the partitions are split up repeatedly, leading to a similar iterative refinement as in the general fixed-point approach.
  The splits are also informed by modal distinctions as explicated by @cleaveland1991explainingBisimInequiv.
  But clever decisions of where to split next and the leaner representation of data allow for more efficient algorithmics.
  However, the nice approach only works if the fixed-point characterization ensures intermediate relations to be *symmetric*.
  This is only the case for bisimilarity, thus heavily restricting the direct applicability of partition refinement.
- **Reduction to bisimilarity.**
  Other equivalences are usually checked by transforming the transition system in some way to make bisimilarity and the respective equivalence coincide on the system [@cleavelandSokolsky2001eqChecking § 3.4].
  A standard example would be to make the transition system deterministic via subset construction, after which trace equivalence can be checked as bisimilarity [@cleavelandHennessy1993testingEq].
- **Term rewriting.**
  If working on process-algebraic terms and similar formalisms, equivalence can also be established through equational reasoning [@mayr2000procRewriteSystems].
  This approach requires a behavioral *congruence* with an axiomatic characterization which processes to consider as equal.
  Intuitively, the algorithm then searches ways of rewriting one process into another.
  But the rules usually create an infinite search space, only allowing semi-decision procedures.
  Together with the coupling to specific process calculi, the approach thus is better fit for the context of proof assistants than for general equivalence checkers.
  However, proofs on axiomatic characterizations often contain normalizations that can inform the design of reductions to bisimilarity.
- **Characteristic formulas.**
  Equivalence can also be handled through characteristic modal formulas [@steffen1989characteristicFormulae].
  Intuitively, one constructs a formula for a state that is precisely true for all conceivable equivalent states.
  Checking equivalence with another state then boils down to model checking the formula on that state.
  However, this approach requires a more complex language of *recursive* modal formulas and remains mostly academic, as no major tools use it for equivalence checking.

{{< paragraph_heading "Modal logics point the way." >}}
We have observed that behavioral equivalences form hierarchies and that these hierarchies are handled nicely using modal characterizations to rank distinguishing powers (@sec-perks-modal-characterizations).

We have also seen how to link game rules to productions in a language of potentially distinguishing formulas (@sec-bisim-game-hml).
This departs from common textbook presentations that motivate the bisimulation game through the relational (coinductive) characterization [e.g. @sangiorgi2012].
In later chapters, we will rather derive equivalence games from grammars of modal formulas (@idea-modal-first), to generalize the framework of @fig-game-algo-overview from bisimilarity to whole spectra of equivalence.

But first, we have to make formal what we mean by *spectra of behavioral equivalence*.
